---
title: "LEAD Data Analysis"
format: html
---

# Load packages

```{r, warning=FALSE, echo=FALSE, output = FALSE, include=FALSE}
library(flextable)
library(table1)
library(dplyr)
library(tibble)
library(misty)
library(officer)
library(tidyverse)
library(readr)
library(purrr)
library(stringr)
library(mice)
library(lubridate)
library(writexl)
library(readxl)
```

# Load cleaned data

Load the participant, self report, LEAD panel assessment,LEAD panel meeting attendance, observational measures and sociodemographic information datasets

```{r}
#| warning: false
socio_demo <- readRDS("../data/cleaned_rds_files/sociodemographic_information_import.rds")
observational_measures <- readRDS("../data/cleaned_rds_files/observational_measures_import.rds")
lead_panel_assessment <- readRDS("../data/cleaned_rds_files/lead_panel_assessment_import.rds")
participant <- readr::read_rds("../data/cleaned_rds_files/participant_import.rds")
lead_attendance <- read_excel("../data/lead_panel_meeting_attendance_reports/Combined LEAD panel meeting attendance.xlsx")
```

# Load User Defined Function Files
```{r}
# Create summary of unique cases
source("../user_defined_functions/unique_case_count.R")

# Create summary of dissenting votes by discipline
source("../user_defined_functions/vote_agreement.R")
```


# Data preparation

Prepare and then merge the relevant variables in the self report, LEAD panel assessment and sociodemographic information data sets into one data frame.

## Participant data

This data was collected by MedStar at the initial 911 response. It includes the results of the initial DETECT screening. We will need those screening results below to compare with LEAD panel findings. 

We will need the results of the DETECT tool filled out at the initial 911 call because we want to be able to say, "At the initial 911 response the DETECT tool was [positive/negtive] for EM. The lead panel then reviewed the case and determined that EM [was/was not] occuring. X porportion of the time, the initial DETECT screening and the LEAD panel determination agreed with each other."


```{r}
#| eval: false

# Look for duplicate by (MedStar ID) records
participant |> 
  group_by(medstar_id) |> 
  count() |> 
  filter(n > 1)

# 2023-08-01: No duplicate rows by MedStar ID
```

```{r}
# Keep only the columns of interest
parti <- participant |> 
  select(
    medstar_id, x_created_timestamp, x_record_month, x_record_year,
    incident_timestamp, unit_arrived_timestamp, complaint_reported,
    age, incident_result, symptom_list, xc_detect_positive_summary_count,
    x_caregiver_lack_knowledge_2cat_f:xc_detect_status_2cat_f
  )
```

## Sociodemographic Information

This data was collected during the DETECT follow-up interview. It includes participant sociodemographic information like race, household income and others. We will compare LEAD screening results across different sociodemographic categories. 

```{r}
# Select relevant variables of interest from sociodemographic information df
soc_dem <- socio_demo %>%
  select(medstar_id, sode_hispanic_4cat_f, sode_race : other, sode_income_9cat_f)

```

## MedStar Medic Assessment (Observational Measures Dataset)

This data comes from the DETECT follow-up interviews. It is a collection of medic EM responses to questions about whether or not they believe abuse has occurred based on provided definitions, signs and symptoms. We will compare these the Medic EM Assessment results to the LEAD Panel Assessment results.

```{r}
obs_meas <- observational_measures %>% 
  select(medstar_id, at_physical_4cat_f: at_self_4cat_f)
```

### Any positive determinations across all subtypes

Create a factor column 'medic_abuse_any' that indicates if an EM medic believes at least one type of abuse is present or none is present.

```{r}
obs_meas <- obs_meas %>%
  mutate(
    medic_abuse_any = case_when(
      if_any(at_physical_4cat_f : at_self_4cat_f, ~. == "Yes")  ~ 1,
      if_all(at_physical_4cat_f : at_self_4cat_f, ~. == "No")   ~ 0,
      TRUE                                                      ~ NA
    )
  )%>%
  mutate(
    medic_abuse_any = factor(
      medic_abuse_any,
      levels = c(0, 1),
      labels = c("No", "Yes")
    )
  )
```

## LEAD Panel Assessment

This data comes from participant abuse assessments by a Longitudinal, Experts, All Data (LEAD) panel. It will be analysed using variables in the sociodemographic, participant and observational measures datasets.

```{r}
# Select relevant variables from LEAD panel assessment df
lpa <- lead_panel_assessment %>%
  select(medstar_id, panelist_name_10cat_f, panelist_discipline_5cat_f, healthcare_worker_2cat_f, x_created_timestamp, x_assessment_month, x_assessment_year, assessment_type_3cat_f : xc_assessment_screened_2cat_f)
```

```{r}
# Subset with initial assessment only
initial_e <- lpa %>% filter(assessment_type_3cat_f == "Initial assessment")

# Subset with Secondary assessment only
secondary_e <- lpa %>% filter(assessment_type_3cat_f == "Secondary assessment")

# Subset with Post-detect assessment only
post_detect_e <- lpa %>% filter(assessment_type_3cat_f == "Post-detect assessment")
```

### ðŸ”´ Panelist multiple assessment data error

Look at medstar_id 47311d550da4471297501ae2b3b03b02. It looks like Jason completed two initial assessments, which shouldn't happen. My guess is that the second initial assessment should have been a secondary assessment and he accidentally clicked the wrong option in FM Pro. We could check this by:
1. Check to see if the there is already a secondary assessment for Jason for 47311d550da4471297501ae2b3b03b02.
2. Check the time stamp on the votes. The secondary assessment should come after the initial assessment (probably on a different day).
3. If there truly are multiple initial assessments, then we need to check if there is any difference between them. If not, then just keep the final row (in terms of time stamp).
4. If there ARE differences, this is trickier. I'm leaning towards keeping the final row here too, but we should look at some examples before making a final decision.


##### Identify Medstar IDs with data error and remove rows based on certain criteria.

Write code that identifies the specific issues, indicates whether a row should be excluded or not and then removes the identified rows based on the following criteria:
  1. Identical duplicates: Keep the most recent row.
  2. Additional entries with all values missing : Remove rows with all missing vote values
  3. Additional entries where not all values are missing: Keep only the most recent

```{r}
  # Create a vector of columns that will be used for grouping below.
group <- c('assessment_type_3cat_f', 'physical_abuse_2cat_f', 'sexual_abuse_2cat_f', 'emotional_psycho_abuse_2cat_f', 'neglect_2cat_f', 
           'self_neglect_2cat_f', 'financial_exploitation_2cat_f', 'abandonment_2cat_f')

# Add a column to the data frame -- multiple_count -- that is equal to the number of rows in the data frame for each combination of medstar ID 
# and panelist name.
multiple_assessment <- lpa %>%
  group_by(medstar_id, panelist_name_10cat_f, assessment_type_3cat_f) %>% 
  mutate(
    multiple_count = length(panelist_name_10cat_f)
  ) %>%
  ungroup()

# For each MedStar ID, are all the scores assigned by the same panelist identical or different (identifies whether or not there is more than one row per group).
multiple_assessment <- multiple_assessment |> 
  group_by(
    medstar_id, panelist_name_10cat_f, assessment_type_3cat_f, sexual_abuse_2cat_f, emotional_psycho_abuse_2cat_f, neglect_2cat_f,
    self_neglect_2cat_f, financial_exploitation_2cat_f, abandonment_2cat_f
  ) %>%
  mutate(
    same_score = case_when(
      multiple_count   >1 & n() > 1  ~ TRUE,
      multiple_count   >1 & n() == 1 ~ FALSE,
      TRUE                           ~ NA 
    )
  ) %>%
  ungroup()

# Are all, some. or none of the assessment values missing for the specified row?
multiple_assessment <- multiple_assessment |> 
  mutate(
    all_na = case_when(
      if_all(all_of(group), ~ is.na(.))  ~ "all",
      if_all(all_of(group), ~ !is.na(.)) ~ "none",
      TRUE                               ~ "some"
    )
  ) %>%
  ungroup()

# For each MedStar ID with multiple assessments for the same panelist, were 
# the assessments performed within one day of each other?
multiple_assessment <- multiple_assessment |>
  group_by(medstar_id, panelist_name_10cat_f, assessment_type_3cat_f) %>%
  mutate(
    over_24_hours = ifelse(
      (as.numeric(difftime(last(x_created_timestamp), first(x_created_timestamp), units = "hours")) > 24), 1, 0
    )
  )

# For each MedStar ID with multiple assessments for the same panelist, was the entry for the specified row the most recent?
multiple_assessment <- multiple_assessment |>
  mutate(
    most_recent = ifelse(x_created_timestamp == max(x_created_timestamp), "Yes", "No")
  )

# Should this row be removed or is further review required to determine this 
# based on the rules below?
multiple_assessment <- multiple_assessment |>
  mutate(
    remove  = case_when(
      # Case when the error is present and the scores are not identical. All of the rows being compared have one or more missing
      # scores and at least one of the rows being compared does not have all of the scores missing. Marks such cases
      # for individual review
      multiple_count > 1 & same_score == FALSE & all(all_na != "none") & any(all_na != "all") ~ "Individual review",
      
      # Case when the error is present, the scores are not identical and at least one of the rows being compared has some but not all 
      # scores missing. Any of the other rows being compared could have none or all missing values. Marks such cases for
      # individual reveiw.
      multiple_count > 1 & same_score == FALSE & any(all_na == "some")                        ~ "Individual review",
      
      # Case when the error is present, the scores are not identical and all the rows being compared have no missing scores.
      multiple_count > 1 & same_score == FALSE & all(all_na == "none")                        ~ "Individual review",
      
      # case when there is no error
      multiple_count == 1                                                                     ~ "No",
      
      # Marks only the most recent of identical rows where error is present for keeping while the other rows are removed.
      multiple_count > 1 & same_score == TRUE & most_recent == "Yes"                          ~ "No",
      
      # Case when there is an error and the scores being compared are not the same. Marks rows where there are no missing scores
      # for keeping
      multiple_count > 1 & same_score == FALSE & all_na == "none"                             ~ "No",
      
      # Case when error is present but all the rows are identical in terms of assigned scores. Marks rows that are not the most
      # recent for removal
      multiple_count > 1 & same_score == TRUE & most_recent == "No"                           ~ "Yes",
      
      # Case when the error is present and the scores are not identical. Marks rows where all the scores are missing for removal
      multiple_count > 1 & same_score == FALSE & all_na == "all"                              ~ "Yes"
    )
  ) %>% 
  ungroup()
# Remove rows marked for removal.
lpac <-  multiple_assessment %>% filter(!(remove == "Yes")) 

# Remove rows marked for individual review that are not the most recent.
lpac <-  lpac %>% filter(!(remove == "Individual review" & most_recent == "No") | remove == "No")


```

### ðŸ”´ Create overall EM determination columns

Create a data frame that summarizes the lead panel data by including columns that indicate:
  - The total number of positive votes
  - The proportion of positive votes
  - Whether there are any positive votes for each type of abuse for each assessment.
  - Whether there are any positive votes across all subtypes of abuse for each assessment.
  - The final LEAD Assessment determination based on majority vote for each assessment.

#### The total number of  positive votes and the proportion of positive votes for each MedStar ID

```{r}
pos_votes <- lpac %>% 
  group_by(medstar_id, assessment_type_3cat_f) %>% 
  reframe(
    # compute the sum of positive votes for each MedStar ID in each assessment
    across(
      .cols  = c(physical_abuse_2cat : abandonment_2cat, xc_assessment_screened_2cat),
      .fns   = ~ sum(.x),
      .names = "{col}_t"
    ),
    assessment_type_3cat_f  = unique(assessment_type_3cat_f),
    # compute the proportion of positive votes for each MedStar ID
    across(
      .cols  = physical_abuse_2cat_t : xc_assessment_screened_2cat_t,
      .fns   = ~ case_when(
        .x   == 0  ~ 0,
        .x  !=  0  ~ .x/n()
      ),
      .names = "{col}_p"
    )
  ) %>%
  # rename the new columns
  rename_with(
    .cols   = ends_with("_t"), 
    .fn     = ~ gsub("2cat_t", "total", .x)
  ) %>% 
  rename_with(
    .cols   = ends_with("_p"), 
    .fn     = ~ gsub("2cat_t_p", "prop", .x)
  )
```

#### Dichotomous variable that indicates if there were _any_ positive determinations at each assessment (initial, secondary, and post-DETECT) for each subtype of abuse.

```{r}

  any_pos <- pos_votes %>% 
    group_by(assessment_type_3cat_f) %>%
    mutate(
      across(
        .cols   = physical_abuse_total : xc_assessment_screened_total,
        .fn     = ~ case_when(
          .x    == 0 ~ 0,
          .x    >  0 ~ 1
        ),
        .names  = "{col}_any"
      ),
      across(
        .cols   = ends_with("_any"),
        .fns    = ~ factor(.x, 
                           levels = c(0,1),
                           labels = c("No", "Yes")),
        .names = "{col}"
      )
    ) %>%
    rename_with(
      .cols   = ends_with("_any"), 
      .fn     = ~ gsub("total_any", "any", .x)
    ) %>%
    ungroup()
```

#### The final LEAD Assessment determination based on majority vote

```{r}
final_det <- any_pos %>% 
  group_by(assessment_type_3cat_f) %>%
  mutate(
    across(
      .cols   = physical_abuse_prop : xc_assessment_screened_prop,
      .fn     = ~ case_when(
        .x    <= 0.5         ~ 0,
        .x    >  0.5         ~ 1
      ),
      .names  = "{col}_det"
    ),
    across(
      .cols   = ends_with("_det"),
      .fns    = ~ factor(.x, 
                    levels = c(0,1),
                    labels = c("No", "Yes")),
    .names = "{col}"
    )
  ) %>%
  rename_with(
    .cols   = ends_with("_det"), 
    .fn     = ~ gsub("prop_det", "det", .x)
  ) %>%
    ungroup()
```

#### Dichotomous variable that indicates if there were _any_ positive determinations at each assessment (initial, secondary, and post-DETECT) across _all_ subtypes of EM.

```{r}
  final_det <- final_det %>%
    group_by(assessment_type_3cat_f) %>%
    mutate(
      abuse_any = case_when(
        if_any(physical_abuse_det : abandonment_det, ~. == "Yes")  ~ 1,
        if_all(physical_abuse_det : abandonment_det, ~. == "No")   ~ 0,
        TRUE                                                       ~ NA
      )
    ) %>%
    mutate(
      abuse_any = factor(
        abuse_any,
        levels = c(0, 1),
        labels = c("No", "Yes")
      )
    ) %>%
    ungroup()
```

## Set labels

```{r}
# Overall final determination
label(final_det$physical_abuse_det)         <- "LEAD physical abuse determination"
label(final_det$sexual_abuse_det)           <- "LEAD sexual abuse determination"
label(final_det$emotional_psycho_abuse_det) <- "LEAD emotional-psycho abuse determination"
label(final_det$neglect_det)                <- "LEAD neglect determination"
label(final_det$self_neglect_det)           <- "LEAD self-neglect determination"
label(final_det$financial_exploitation_det) <- "LEAD financial exploitation determination"
label(final_det$abandonment_det)            <- "LEAD abandonment determination"
label(final_det$abuse_any)                  <- "LEAD any abuse determination"

# Socio-demographic variables
label(soc_dem$sode_hispanic_4cat_f)                      <- "Ethnicity (Hispanic)"
label(soc_dem$american_indian_or_alaska_native)          <- "American Indian or Alaska Native"
label(soc_dem$asian)                                     <- "Asian"
label(soc_dem$black_or_african_american)                 <- "Black or African American"
label(soc_dem$native_hawaiian_or_other_pacific_islander) <- "Native Hawaiian or Other Pacific Islander"
label(soc_dem$white)                                     <- "White"
label(soc_dem$other)                                     <- "Other"
label(soc_dem$sode_income_9cat_f)                        <- "Household Income"

# Observational measures variables
label(obs_meas$at_physical_4cat_f)   <- "Medic EM physical abuse assessment"
label(obs_meas$at_sexual_4cat_f)     <- "Medic EM sexual abuse assessment"
label(obs_meas$at_emotional_4cat_f)  <- "Medic EM emotional abuse assessment"
label(obs_meas$at_neglect_4cat_f)    <- "Medic EM neglect assessment"
label(obs_meas$at_abandon_4cat_f)    <- "Medic EM abandonment assessment"
label(obs_meas$at_financial_4cat_f)  <- "Medic EM financial abuse assessment"
label(obs_meas$at_self_4cat_f)       <- "Medic EM self-neglect assessment"
label(obs_meas$medic_abuse_any)      <- "Medic EM any abuse assessment"
label(parti$age)                     <- "Age (in years)"
label(parti$xc_detect_status_2cat_f) <- "Abuse determination at initial 911 call"
```

## Create a separate data frame for each assessment type

```{r}
# Initial
initial_pos_votes <- final_det %>% filter(assessment_type_3cat_f == "Initial assessment")

# Secondary
secondary_pos_votes <- final_det %>% filter(assessment_type_3cat_f == "Secondary assessment")

# Post-DETECT
post_detect_pos_votes <- final_det %>% filter(assessment_type_3cat_f == "Post-detect assessment")
```

## Merge the initial_pos_votes and secondary_pos_votes data sets, keeping only the secondary_pos_votes for each medstar_id when it is available

```{r}
final_determination <- initial_pos_votes[!initial_pos_votes$medstar_id %in% secondary_pos_votes$medstar_id,]
final_determination <- rbind(final_determination, secondary_pos_votes)
```

## Participants who with a positive abuse LEAD Panel Assessment determination for any abuse type.

```{r}
part_id <- participant %>% select(medstar_id, name_full)

any_pos_abuse <- final_determination %>% select(medstar_id, assessment_type_3cat_f, abuse_any) %>% filter(abuse_any == "Yes")

pos_det <- purrr::reduce(list(part_id, any_pos_abuse), dplyr::right_join, by = 'medstar_id')

# Save list as an Excel sheet
# write_xlsx(pos_det, "LEAD_positive_determination_list.xlx")
```



## Merge participant, observational measures, sociodemographic and LEAD dateframes

```{r}
# Merge subset dfs into a new df
final_determination <- purrr::reduce(list(final_determination, soc_dem, obs_meas, parti), dplyr::left_join, by = 'medstar_id')
final_det_initial   <- purrr::reduce(list(initial_pos_votes, soc_dem, obs_meas, parti), dplyr::left_join, by = 'medstar_id')
final_det_sec       <- purrr::reduce(list(secondary_pos_votes, soc_dem, obs_meas, parti), dplyr::left_join, by = 'medstar_id')
final_det_post      <- purrr::reduce(list(post_detect_pos_votes, soc_dem, obs_meas, parti), dplyr::left_join, by = 'medstar_id')
```

## Merge the separate assessment type data frames into one.
```{r}
# Create a data frame that is a combination of the three dataframes containing the final abuse determination summaries for all 3 assessment types.
lead_panel_det <- rbind(initial_pos_votes, secondary_pos_votes, post_detect_pos_votes)

```

## Create dataframe containing "any abuse" determinations across the 3 assessments
This will be used to check the percent similarity of the final abuse determinations across the assessments.

```{r}
# Create a subset data frame with only the needed columns and rename columns to distinguish the initial assessment columns from those of the other assessments
initial_compare <- initial_pos_votes %>% 
  select(medstar_id, physical_abuse_det : abandonment_det, abuse_any) %>%
  rename(abuse_any_initial = abuse_any) %>%
    rename_with(
      .cols   = c(ends_with("_det")), 
      .fn     = ~ gsub("det", "det_init", .x)
    )

# Create a subset data frame with only the needed columns and rename columns to distinguish the secondary assessment columns from those of the other assessments
secondary_compare <- secondary_pos_votes %>% 
  select(medstar_id, physical_abuse_det : abandonment_det, abuse_any) %>%
  rename(abuse_any_sec = abuse_any) %>%
    rename_with(
      .cols   = c(ends_with("_det")), 
      .fn     = ~ gsub("det", "det_sec", .x)
    )

# Create a subset data frame with only the needed columns and rename columns to distinguish the post-DETECT assessment columns from those of the other assessments
post_compare <- post_detect_pos_votes %>% 
  select(medstar_id, physical_abuse_det : abandonment_det, abuse_any) %>%
  rename(abuse_any_post = abuse_any) %>%
    rename_with(
      .cols   = c(ends_with("_det")), 
      .fn     = ~ gsub("det", "det_post", .x)
    )

# Merge the above 3 data frames into one data frame
assessment_compare <- purrr::reduce(list(initial_compare, secondary_compare, post_compare), dplyr::left_join, by = 'medstar_id') %>%
  mutate(
    same_is = ifelse(is.na(abuse_any_sec), NA, 
      ifelse(abuse_any_initial == abuse_any_sec, 1,0)
      ),
    same_ip = ifelse(is.na(abuse_any_post), NA, 
                      ifelse(abuse_any_initial == abuse_any_post, 1,0)
    ),
    same_ii = ifelse(is.na(abuse_any_initial), NA, 
                      ifelse(abuse_any_initial == abuse_any_initial, 1,0)
    )
  )

```


## Participants interviewed between 05/2022 and 05/2023 with positive screening based on LEAD panel abuse determination 

This subset will be contacted for interviews for sharing their experiences.

```{r}
# Medic F/U assessment Medic abuse determination timestamp
med_time <- observational_measures %>% 
  select(medstar_id, x_created_timestamp)

# Add names from participant data frame since some are missing in the  LEAD assessment data frame. And include column showing participant's willingness to receive another phone call.
names <- participant %>% 
  select(medstar_id, name_full, x_do_not_call_2cat_f, phone)

# Add any_abuse variable from final_det_initial df.

abuse <- final_det_initial %>%
  select(medstar_id, abuse_any)

# Merge data sets and create participant list
interview_list <- purrr::reduce(list(abuse, names, med_time), dplyr::left_join, by = 'medstar_id') %>% 
  filter(
  as_date(x_created_timestamp) >= as_date("2022-05-01") & 
    as_date(x_created_timestamp) <= as_date("2023-05-31") &
    abuse_any == "Yes"
) %>% 
  select(medstar_id, name_full, x_created_timestamp, abuse_any, x_do_not_call_2cat_f, phone)

# Save list as an Excel sheet
# write_xlsx(interview_list, "interview_list.xlsx")
```

## LEAD panelist data metrics

Prepare the data to extract LEAD panel metric requested by Dr. Pickering.

### Paticipation of unique panelists per month across all assessment types

```{r}
# Remove the columns used for identifying rows with the data error.
lpac <- lpac %>% select(-c(multiple_count: remove))

# Create a date column combining month and year and including a placeholder value for day
lpac <- lpac %>%
  mutate(
    day = 1,
    x_assessment_month_num = dplyr::recode(x_assessment_month,
                                    January   = 1,
                                    February  = 2,
                                    March     = 3,
                                    April     = 4,
                                    May       = 5,
                                    June      = 6,
                                    July      = 7,
                                    August    = 8,
                                    September = 9,
                                    October   = 10,
                                    November  = 11,
                                    December  = 12
    )
  ) %>% 
  mutate(
    assessment_date = make_date(year  = x_assessment_year,
                                month = x_assessment_month_num, day = day)
  )

# Create a data frame containing only the participation dates and names of unique panelists
panelist_participation <- lpac %>% 
  group_by(assessment_date) %>%
  reframe(
    unique_panelist = unique(panelist_name_10cat_f),
    attendance = length(unique(panelist_name_10cat_f))
  )
# Create a data frame that shows the number of unique panelists per month that participated in LEAD meetings
unique_panelist_participation <- panelist_participation %>% 
  select(assessment_date, attendance) %>% unique()
```

### Average meeting attendance

Average meeting attendance is the number of unique people who filled out a secondary assessment each month.

```{r}
# Create a dataframe containing only the months and names of unique panelists that voted in the secondary assessment.
sec_meeting_attendance <- lpac %>%
  filter(assessment_type_3cat_f == "Secondary assessment") %>%
  group_by(assessment_date) %>%
  reframe(
    unique_panelist = unique(panelist_name_10cat_f),
    attendance = length(unique(panelist_name_10cat_f))
  )

unique_secondary_attendance <- sec_meeting_attendance %>% 
  select(assessment_date, attendance) %>% unique()
```

### Average meeting length from 7/22/2020 to 5/24/2023

```{r}
# Create meeting_date column and re-format attendance_duration variable as numerical
lead_attendance <- lead_attendance %>% 
  mutate(
    meeting_date        = as_date(meeting_start_time),
    attendance_duration_mins = as.numeric(gsub(" min.*", "", attendance_duration)
                                     )
    )


# Find average meeting length using the longest attendance duration per date. 
meeting_duration <- lead_attendance %>% group_by(meeting_date) %>% 
  reframe(
    meeting_time = max(attendance_duration_mins)
  )
```

### Unique panelists per assessment type

Create data frames to extract information on the unique panelists that voted in each assessment and across all assessments. 

```{r}
initial_panelists     <- lpac %>% filter(assessment_type_3cat_f == "Initial assessment") %>% ungroup() %>%
  select(panelist_name_10cat_f) %>% unique()
secondary_panelists   <- lpac %>% filter(assessment_type_3cat_f == "Secondary assessment") %>% ungroup() %>%
  select(panelist_name_10cat_f) %>% unique() 
post_panelists        <- lpac %>% filter(assessment_type_3cat_f == "Post-detect assessment")%>% ungroup() %>%
  select(panelist_name_10cat_f) %>% unique() 
```

# Analaysis

## Missing data summary

```{r, fig.width = 20}
fd_m <- final_determination %>% 
  select(
    physical_abuse_det: at_self_4cat_f,  
    )%>% md.pattern(., plot = T, rotate.names = T)
```

## Number and proportion of assessements completed by type of assesement

```{r}
sum_table <- unique_case(lpac, medstar_id, assessment_type_3cat_f) %>%
  flextable()
# Set caption

sum_table <- set_caption(sum_table, "Summary of Unique Medstar IDs for the LEAD Assessment Data")
sum_table <- width(sum_table, width = 1.8)


sum_table
```

## Percent Similarity of determinations between the different assessments

Create a table that shows the percent similarity between each of the three assessment types and each of the other types using the dataframe containing "any abuse" determination across the 3 assessments. 

Answers the question: When comparing the one assessment type to the other, what is the percentage of determinations that were the same in another assessment type, using the the smaller variable as the denominator?

### Function
This function takes the name of a variable in the assessment_compare df that indicates whether or not the abuse determinations are the same for specified variables as an input. It computes the percent of abuse determinations that are the same rounded to 2 decimal places.  
```{r}
similarity <- function(column){
  round(length(which(assessment_compare[[column]] == 1))/length(which(!is.na(assessment_compare[[column]]) == TRUE))*100, digits = 2)  
}
```

### Values
```{r}
# Create values for the table
ii = similarity("same_ii")
is = similarity("same_is")
ip = similarity("same_ip")
```

### Format table
```{r}
sim_table <- data.frame(
                        Value = c("Initial", "Secondary", "Post-DETECT"),
                        Initial     = c(ii, is, ip) 
                        ) %>%
  flextable()
# Set caption
sim_table <- set_caption(sim_table, "Table Showing the Percent Similarity Between the Initial Assessment Determination and the Other Assessment Types")

# format line
std_border = fp_border(color="black")

# Set header labels 

sim_table <- set_header_labels(sim_table, Value = "")
sim_table <- set_header_labels(sim_table, Post_detect = "Post-DETECT")

sim_table <- width(sim_table, width = 2)
sim_table <- vline(sim_table, j = 1, border = std_border)

sim_table
```

## LEAD data metrics requested by Dr. Pickering

### Metrics

I understand people could vote 3 times as they got additional information/discussion -- how many people did that? interpreted as: How many LEAD panelists voted in all three assessments (initial, secondary, post-detect)

```{r}
voted_in_all <- Reduce(intersect, list(initial_panelists, secondary_panelists, post_panelists)) %>% nrow()
cat("Total number of unique panelists that voted in all three assessments =", voted_in_all)
```
The number of unique panelists that voted in the initial assessment

```{r}
initial_voters <- initial_panelists %>% nrow()
cat("Number of unique panelists that voted in the initial assessment =", initial_voters)
```
The number of unique panelists that voted in the secondary assessment

```{r}
secondary_voters <- secondary_panelists %>% nrow()
cat("Number of unique panelists that voted in the secondary assessment =", secondary_voters)
```

The number of unique panelists that voted in the post-DETECTl assessment

```{r}
post_voters <- post_panelists %>% nrow()
cat("Number of unique panelists that voted in the post-DETECT assessment =", post_voters)
```

The number of people who were asked to be on LEAD and the number who agreed. Everyone who was asked agreed.  

```{r}
all_voters <- Reduce(union, list(initial_panelists, secondary_panelists, post_panelists)) %>% nrow()
cat("Total number of unique panelists across all three assessments =", all_voters)
```

Average meeting attendance. The average meeting attendance is the number of unique people who filled out a secondary assessment each month.

```{r}
cat("Average meeting attendance =", mean(unique_secondary_attendance$attendance))
```
Average meeting length from 7/22/2020 to 5/24/2023

```{r}
cat("Average meeting length =", mean(meeting_duration$meeting_time))
```

### Plot
Create a plot that shows the number of unique panelists that participated per month over time.

```{r}
participation <- ggplot(aes(x = assessment_date, y = attendance), data = unique_panelist_participation) + geom_line() +
  labs(title = "Number of Unique Panelists Per Month Over Time ", x = "Time", 
       y = "Number of Unique Panelists Per Month")

participation

ggsave("participation_plot.png")
```

### Abuse types of the dissimilar cases
For the cases that did not have congruence â€“ what type of cases were they? (physical, self-neglect, etc)

#### Initial vs Secondary

##### Create dummy variables that indicate the type of case 

```{r}
# Dissimilar cases between the initial and secondary assessments
sec_dissimilar <- assessment_compare %>% filter(same_is == 0) %>% select(-c(same_ip, same_ii, ends_with("_post")))
```

```{r}
sec_dissimilar <- sec_dissimilar %>% 
  mutate(
    non_con_phys = ifelse(physical_abuse_det_init != physical_abuse_det_sec, 1, 0),
    non_con_sex  = ifelse(sexual_abuse_det_init != sexual_abuse_det_sec, 1, 0),
    non_con_emo  = ifelse(emotional_psycho_abuse_det_init != emotional_psycho_abuse_det_sec, 1, 0),
    non_con_neg  = ifelse(neglect_det_init != neglect_det_sec, 1, 0),
    non_con_self = ifelse(self_neglect_det_init != self_neglect_det_sec, 1, 0),
    non_con_fin  = ifelse(financial_exploitation_det_init != financial_exploitation_det_sec, 1, 0),
    non_con_aban = ifelse(abandonment_det_init != abandonment_det_sec, 1, 0),
    total        = rowSums(
      across(
        .cols = non_con_phys : non_con_aban
      )
    )
  )
```

##### Values
```{r}
# Create values for the table
phys = sec_dissimilar %>% filter(non_con_phys == 1) %>% nrow()
sex = sec_dissimilar %>% filter(non_con_sex == 1) %>% nrow()
emo = sec_dissimilar %>% filter(non_con_emo == 1) %>% nrow()
neg = sec_dissimilar %>% filter(non_con_neg == 1) %>% nrow()
self = sec_dissimilar %>% filter(non_con_self == 1) %>% nrow()
fin = sec_dissimilar %>% filter(non_con_fin == 1) %>% nrow()
aban = sec_dissimilar %>% filter(non_con_aban == 1) %>% nrow()
```

##### Format table
```{r}
case_table <- data.frame(
                        Value = c("Physical abuse", "Sexual abuse", "Emotional abuse", "Neglect",
                                  "Self-neglect", "Financial abuse","Abandonment"),
                        Count     = c(phys, sex, emo, neg, self, fin, aban),
                        Proportion = c(phys/21, sex/21, emo/21, neg/21, self/21, fin/21, aban/21)
                        ) %>%
  flextable()
# Set caption
case_table <- set_caption(case_table, "Non-congruent Cases Between Initial Assessment Determination and Secondary Assessment (Total non-congruent cases = 21)")


# Set header labels 

case_table <- set_header_labels(case_table, Value = "Abuse Types")

case_table <- width(case_table, width = 2)

case_table <- add_footer_lines(case_table, values = c("In one case, 2 types of abuse (emotional and financial) were detected simultaneously."))

case_table <- italic(case_table, italic = TRUE, part = "footer")

case_table

```

#### Initial vs Post-DETECT

##### Create dummy variables that indicate the type of case 

```{r}
# Dissimilar cases between the initial and secondary assessments
post_dissimilar <- assessment_compare %>% filter(same_ip == 0) %>% select(-c(same_is, same_ii, ends_with("_sec")))
```

```{r}
post_dissimilar <- post_dissimilar %>% 
  mutate(
    non_con_phys = ifelse(physical_abuse_det_init != physical_abuse_det_post, 1, 0),
    non_con_sex  = ifelse(sexual_abuse_det_init != sexual_abuse_det_post, 1, 0),
    non_con_emo  = ifelse(emotional_psycho_abuse_det_init != emotional_psycho_abuse_det_post, 1, 0),
    non_con_neg  = ifelse(neglect_det_init != neglect_det_post, 1, 0),
    non_con_self = ifelse(self_neglect_det_init != self_neglect_det_post, 1, 0),
    non_con_fin  = ifelse(financial_exploitation_det_init != financial_exploitation_det_post, 1, 0),
    non_con_aban = ifelse(abandonment_det_init != abandonment_det_post, 1, 0),
    total        = rowSums(
      across(
        .cols = non_con_phys : non_con_aban
      )
    )
  )
```

##### Values
```{r}
# Create values for the table
phys2 = post_dissimilar %>% filter(non_con_phys == 1) %>% nrow()
sex2 = post_dissimilar %>% filter(non_con_sex == 1) %>% nrow()
emo2 = post_dissimilar %>% filter(non_con_emo == 1) %>% nrow()
neg2 = post_dissimilar %>% filter(non_con_neg == 1) %>% nrow()
self2 = post_dissimilar %>% filter(non_con_self == 1) %>% nrow()
fin2 = post_dissimilar %>% filter(non_con_fin == 1) %>% nrow()
aban2 = post_dissimilar %>% filter(non_con_aban == 1) %>% nrow()
```

##### Format table
```{r}
case2_table <- data.frame(
                        Value = c("Physical abuse", "Sexual abuse", "Emotional abuse", "Neglect",
                                  "Self-neglect", "Financial abuse","Abandonment"),
                        Count     = c(phys2, sex2, emo2, neg2, self2, fin2, aban2),
                        Proportion = c(phys2/12, sex2/12, emo2/12, neg2/12, self2/12, fin2/12, aban2/12)
                        ) %>%
  flextable()
# Set caption
case2_table <- set_caption(case2_table, "Non-congruent Cases Between Initial Assessment Determination and Post-DETECT Assessment (Total non-congruent cases = 12)")


# Set header labels 

case2_table <- set_header_labels(case2_table, Value = "Abuse Types")

case2_table <- width(case2_table, width = 2)

case2_table
```

### LEAD Panelist Votes

For each LEAD panel member, how many initial votes did they have? How many secondary votes did they have? How often did their initial vote change at the secondary vote?


#### Prepare the data
```{r}
init_sec <- lpac %>%
  # Select only the needed columns
  select(c(medstar_id, assessment_type_3cat_f, panelist_name_10cat_f, physical_abuse_2cat_f : abandonment_2cat))

# Create a subset data frame with only the initial assessment rows and rename the abuse columns to distinguish them from those of the secondary assessment
initial_panelist_votes <- init_sec %>%
  filter(assessment_type_3cat_f ==  "Initial assessment") %>%
  select(-c(assessment_type_3cat_f)) %>%
  rename_with(
    .cols   = c(ends_with("_2cat_f")), 
    .fn     = ~ gsub("2cat_f", "2cat_init", .x)
  )

# Create a subset data frame with only the secondary assessment rows and rename the abuse columns to distinguish them from those of the initial assessment
sec_panelist_votes <- init_sec %>%
  filter(assessment_type_3cat_f ==  "Secondary assessment") %>%
  select(-c(assessment_type_3cat_f)) %>%
  rename_with(
    .cols   = c(ends_with("_2cat_f")), 
    .fn     = ~ gsub("2cat_f", "2cat_sec", .x)
  )

# Merge the two above data frames into one
panelist_votes <- purrr::reduce(list(sec_panelist_votes, initial_panelist_votes), dplyr::left_join, 
                                by = c('medstar_id', "panelist_name_10cat_f"))

# Create columns that compare the secondary and initial vote for each abuse type
panelist_votes<- panelist_votes %>%
  mutate(
    phys_agree = ifelse(physical_abuse_2cat_sec == physical_abuse_2cat_init, 1, 0),
    sex_agree = ifelse(sexual_abuse_2cat_sec == sexual_abuse_2cat_init, 1, 0),
    emo_agree = ifelse(emotional_psycho_abuse_2cat_sec == emotional_psycho_abuse_2cat_init, 1, 0),
    neg_agree = ifelse(neglect_2cat_sec == neglect_2cat_init, 1, 0),
    self_agree = ifelse(self_neglect_2cat_sec == self_neglect_2cat_init, 1, 0),
    fin_agree = ifelse(financial_exploitation_2cat_sec == financial_exploitation_2cat_init, 1, 0),
    aban_agree = ifelse(abandonment_2cat_sec == abandonment_2cat_init, 1, 0)
  )
```

#### Create the dataframe

```{r}
type_perc_change <- function(a_agree, a_type) {
  # Create data frame that will be used to compute the vote change frequency per abuse type for each panelist
  tab1 <- as.data.frame(addmargins(table(panelist_votes$panelist_name_10cat_f, panelist_votes[[a_agree]]), c(2)))
    
  # Make the data frames tidy
  df1 <- tab1 %>%
    pivot_wider(names_from = Var2, values_from = Freq) %>%
    rename(panelist_name = Var1, 
          n_votes = Sum,
          n_changed_votes = "0") %>%
    select(-c("1")) %>%
    #mutate(
      # create column for the percentage of votes that were changed from the initial to secondary assessment
      #perc_changed = paste0(format(round((n_changed_votes/n_votes)*100, digits = 2), nsmall = 2), " %")
    #) %>%
    #select(-c(n_votes, n_changed_votes)) %>%
    mutate(
      abuse_type = a_type
    )
    
  # Create data frame containing the number of initial and secondary votes per abuse type for each panelist
  tab2 <- as.data.frame(table(lpac$panelist_name_10cat_f, lpac$assessment_type_3cat_f,
                              lpac$physical_abuse_2cat_f))

  # Make the data frames tidy
  df2 <- tab2 %>%
    pivot_wider(names_from = Var3, values_from = Freq) %>%
    rename(yes = "1",
          no = "0") %>%
    mutate(n_votes = yes + no) %>%
    select(-c(yes, no)) %>%
    pivot_wider(names_from = Var2, values_from = n_votes) %>%
    select(-c("Post-detect assessment")) %>%
    rename(panelist_name = Var1, 
          initial_n_votes = "Initial assessment",
          sec_n_votes = "Secondary assessment")

  # Merge the percent changed vote and vote count per assessment data frames
  comb_df <- left_join(df2, df1, by = "panelist_name")
}

# Physical abuse
phys_disc <- type_perc_change("phys_agree", "Physical Abuse")
  
# Sexual abuse
sex_disc <- type_perc_change("sex_agree", "Sexual Abuse")
  
# Emotional-psychological abuse
emo_disc <- type_perc_change("emo_agree", "Emotional-Psychological Abuse")

# Neglect
neg_disc <- type_perc_change("neg_agree", "Neglect")
  
# Self-neglect
self_disc <- type_perc_change("self_agree", "Self-neglect")
  
# Financial Explotation
fin_disc <- type_perc_change("fin_agree", "Financial Exploitation")
  
# Abandonment
aban_disc <- type_perc_change("aban_agree", "Abandonment")
  
# Merge dataframes for each abuse type to create one data frame for all abuse types
panelist_vote_sum <- purrr::reduce(list(phys_disc, sex_disc, emo_disc, neg_disc, self_disc, fin_disc, aban_disc), rbind)
  
# Compute "Overall" rows for each panelist from sum of votes and dissenting votes for all the abuse types 
panelist_vote_sum <- panelist_vote_sum %>%
group_by(panelist_name) %>%
bind_rows(
  reframe(
    .,
    across(
      .cols = c(initial_n_votes, sec_n_votes, n_changed_votes, n_votes),
      .fns  = ~sum(.x)
    ),
    abuse_type = "Overall",
    panelist_name = panelist_name
  )
) %>%
distinct()
  
# Replace the vote count per abuse type and the number of changed votes columns with a column that shows the number of changed votes as a percentage of the vote count per abuse type
panelist_vote_sum <- panelist_vote_sum %>%
  mutate(
    # create column for the percentage of votes that were changed from the initial to secondary assessment
    perc_changed = paste0(format(round((n_changed_votes/n_votes)*100, digits = 2), nsmall = 2), " %")
  ) %>%
    select(-c(n_votes, n_changed_votes)) %>%
  # remove "%" after "NaN"
  mutate(perc_changed = str_replace(perc_changed, "NaN %", "NaN"))
```

#### Format the table

```{r}
# Set border formatting
std_border = fp_border(color="black")

# Convert the data frame into a flextable that groups the data by abuse type
pan_vote <- as_grouped_data(panelist_vote_sum, groups = "abuse_type") %>%
  as_flextable(hide_grouplabel = TRUE) %>%
  
  # Set the table caption
  set_caption("Initial and Secondary Assessment Vote Counts for Each LEAD Panelist and Percentage of Initial Votes that Changed at the Secondary Assessment for Cases that were Voted on In Both Assessments") %>%
  
  # Set table borders
  surround(i = ~ !is.na(abuse_type),
           border = std_border) %>%
  border_outer(part="all", border = std_border) %>%
  vline(border = std_border ) %>%
  
  # Rename and format the header labels
  set_header_labels(panelist_name   = "Panelist Name",
                    initial_n_votes = "N Initial Votes",
                    sec_n_votes     = "N Seconday Votes",
                    perc_changed     = "Percentage of Changed Votes") %>%
  bold(bold = TRUE, part="header") %>%
  
  # Adjust the table width
  width(width = 1.5)

pan_vote

```

### Panelist Disciplines of Non-Congruent Cases

For cases that did not have congruence (or at least initially) â€“ were there certain disciplines that tended to diverge from the others?

```{r}
panelist_vote_agree <- panelist_vote_agreement(lpac)

panelist_vote_agree_flex <- flextable(panelist_vote_agree)

panelist_vote_agree_flex
```



# ðŸ”´ NOTE

Before we analyze race, we want to know the number and proportion of determinations overall. Secondarily, we will repeat the analysis by race/ethnicity (and probably a bunch of other characteristics). Let's don't drop any rows yet that have NA for race/ethnicity. Only drop rows that have NA for determinations (hopefully, there aren't any).

### Determinations Overall

#### Final determinations for the secondary assessment except when not available (initial assessment in this case)

```{r}
# Create caption/ title
cap_1  <- "Abuse Determinations Overall - Secondary LEAD Assessment (Initial When Unavailable)"


overall_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + abandonment_det + financial_exploitation_det + self_neglect_det + abuse_any, 
               data = final_determination, 
               caption = cap_1)
overall_tab <- t1flex(overall_tab, tablefn = c("qflextable", "flextable", "regulartable"))
overall_tab <- width(overall_tab, width = 3)
overall_tab <- bold(overall_tab, bold = FALSE, part = "all")
overall_tab
```

#### Final determinations for the intial assessment

```{r}
# Create caption/ title
cap_1  <- "Abuse Determinations Overall - Initial LEAD Assessment"


initial_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + self_neglect_det +
                        financial_exploitation_det + abandonment_det + abuse_any, 
               data = final_det_initial, 
               caption = cap_1)
initial_tab <- t1flex(initial_tab, tablefn = c("qflextable", "flextable", "regulartable"))
initial_tab <- width(initial_tab, width = 3)
initial_tab <- bold(initial_tab, bold = FALSE, part = "all")
initial_tab
```

#### Final determinations for the secondary assessment

```{r}
# Create caption/ title
cap_1  <- "Abuse Determinations Overall - Secondary LEAD Assessment"


sec_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + self_neglect_det +
                        financial_exploitation_det + abandonment_det + abuse_any, 
               data = final_det_sec, 
               caption = cap_1)
sec_tab <- t1flex(sec_tab, tablefn = c("qflextable", "flextable", "regulartable"))
sec_tab <- width(sec_tab, width = 3)
sec_tab <- bold(sec_tab, bold = FALSE, part = "all")
sec_tab
```

#### Final determinations for the post detect assessment

```{r}
# Create caption/ title
cap_1  <- "Abuse Determinations Overall - Post-Detect LEAD Assessment"


post_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + self_neglect_det +
                        financial_exploitation_det + abandonment_det + abuse_any, 
               data = final_det_post, 
               caption = cap_1)
post_tab <- t1flex(post_tab, tablefn = c("qflextable", "flextable", "regulartable"))
post_tab <- width(post_tab, width = 3)
post_tab <- bold(post_tab, bold = FALSE, part = "all")
post_tab
```

### Race/ Ethnicity stratified by abuse determination

```{r}
# Remove missing rows for LEAD data
fd_na <- final_determination %>% drop_na(physical_abuse_det: 	
xc_assessment_screened_det)
```


#### Abuse Determination Overall by Race/ Ethnicity
The data set includes the Secondary Assessment (initial When unavailable)

```{r}
# Create caption/ title
cap_1  <- "Race/ Ethnicity by LEAD Assessment Abuse Determination"


race_tab <- table1(~ sode_hispanic_4cat_f + american_indian_or_alaska_native + asian + black_or_african_american + native_hawaiian_or_other_pacific_islander + white + other| abuse_any, 
               data = fd_na, 
               caption = cap_1)
race_tab <- t1flex(race_tab, tablefn = c("qflextable", "flextable", "regulartable"))
race_tab <- width(race_tab, width = 1.5)
race_tab <- bold(race_tab, bold = FALSE, part = "all")
race_tab
```

#### Abuse Determination Overall by Household Income
The data set includes the Secondary Assessment (initial When unavailable)

```{r}
# Create caption/ title
cap_1  <- "Household Income by LEAD Assessment Abuse Determination"


income_tab <- table1(~ sode_income_9cat_f | abuse_any, 
               data = fd_na, 
               caption = cap_1)
income_tab <- t1flex(income_tab, tablefn = c("qflextable", "flextable", "regulartable"))
income_tab <- width(income_tab, width = 1.5)
income_tab <- bold(income_tab, bold = FALSE, part = "all")
income_tab
```

#### MedStar Medic and Detect Status at Initial 911 Call vs LEAD Abuse Determination

```{r}
# Create caption/ title
cap_1  <- "MedStar Medic EM Abuse Determinations"


medic_tab <- table1(~ at_physical_4cat_f + at_sexual_4cat_f + at_emotional_4cat_f + at_neglect_4cat_f + at_abandon_4cat_f + at_financial_4cat_f + at_self_4cat_f + medic_abuse_any,
               data = final_determination,
               caption = cap_1)
medic_tab <- t1flex(medic_tab, tablefn = c("qflextable", "flextable", "regulartable"))
medic_tab <- width(medic_tab, width = 3)
medic_tab <- bold(medic_tab, bold = FALSE, part = "all")
medic_tab
```

```{r}
# Create caption/ title
cap_1  <- "Overall MedStar Medic Abuse Determinations and Detect status at Initial 911 Call by Overall LEAD Determinations"


mvl_tab <- table1(~ medic_abuse_any + xc_detect_status_2cat_f | abuse_any,
               data = fd_na,
               caption = cap_1)
mvl_tab <- t1flex(mvl_tab, tablefn = c("qflextable", "flextable", "regulartable"))
mvl_tab <- width(mvl_tab, width = 1.5)
mvl_tab <- bold(mvl_tab, bold = FALSE, part = "all")
mvl_tab
```

# Create LEAD  Data Analysis Word Document

```{r, echo = FALSE}
# create Word file and object
lead_doc <- read_docx()

# Add title
text_style <- fp_text(font.size = 28)
par_style <- fp_par(text.align = "center")

lead_doc <- body_add_fpar(lead_doc, fpar( ftext("LEAD Data Analysis Tables", prop = text_style), 
                                              fp_p = par_style ) ) %>%
  body_add_par(value = "")

# Add number and proportion of assessments completed by type of assessment table
lead_doc <- lead_doc %>% 
  body_add_flextable(sum_table, align = "left") %>%
  body_add_par(value = "")

# Add similarity percentage table
lead_doc <- lead_doc %>%
  body_add_par("The table below answers the question: When comparing the initial assessment abuse determinations to the other assessments, what is the percentage of determinations that were the same?")%>%
  body_add_par(value = "") %>%
  body_add_flextable(sim_table, align = "left") %>%
  body_add_par(value = "")

# Add final determinations for the secondary assessment except when not available (initial assessment in this case) table
lead_doc <- lead_doc %>% 
  body_add_par("LEAD abuse determination was by majority vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)")%>%
  body_add_par(value = "") %>%
  body_add_flextable(overall_tab, align = "left") %>%
  body_add_par(value = "")

# Add final determinations for the intial assessment table
lead_doc <- lead_doc %>% 
  body_add_flextable(initial_tab, align = "left") %>%
  body_add_par(value = "")

# Add final determinations for the secondary assessment table
lead_doc <- lead_doc %>% 
  body_add_flextable(sec_tab, align = "left") %>%
  body_add_par(value = "")

# Add final determinations for the post detect assessment table
lead_doc <- lead_doc %>% 
  body_add_flextable(post_tab, align = "left") %>%
  body_add_par(value = "")

# Add Abuse Determination Overall by Race/ Ethnicity table
lead_doc <- lead_doc %>% 
  body_add_par("LEAD abuse determination was by majority vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)")%>%
  body_add_par(value = "") %>%
  body_add_flextable(race_tab, align = "left") %>%
  body_add_par(value = "")

# Add Abuse Determination Overall by Household Income Table
lead_doc <- lead_doc %>% 
  body_add_par("LEAD abuse determination was by majority vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)")%>%
  body_add_par(value = "") %>%
  body_add_flextable(income_tab, align = "left") %>%
  body_add_par(value = "")

# Add MedStar Medic EM Abuse Determinations Table
lead_doc <- lead_doc %>% 
  body_add_flextable(medic_tab, align = "left") %>%
  body_add_par(value = "")

# Add MedStar Medic and Detect Status at Initial 911 Call vs LEAD Abuse Determination Table
lead_doc <- lead_doc %>% 
  body_add_par("LEAD abuse determination was by majority vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)")%>%
  body_add_par(value = "") %>%
  body_add_flextable(mvl_tab, align = "left")

# Add the percentage dissenting votes for the panelist discipline table
lead_doc <- lead_doc %>%
  body_add_par(value = "") %>%
  body_add_flextable(panelist_vote_agree_flex, align = "left") %>%
  body_add_par(value = "")

# Add the LEAD panelists votes table 
lead_doc <- lead_doc %>%
  body_add_flextable(pan_vote, align = "left") %>%
  body_add_par(value = "")

# print the word document
 print(lead_doc, target = "LEAD_data_analysis_tables.docx")
```

# Export LEAD data feasibility metrics tables and plots into a Word file

```{r}
# create Word file and object
feas_doc <- read_docx()

# Add the Non-congruent Cases Between Initial Assessment Determination and Secondary Assessment table
feas_doc <- feas_doc %>% 
  body_add_flextable(case_table, align = "left") %>%
  body_add_par(value = "")

# Add the Non-congruent Cases Between Initial Assessment Determination and Post-DETECT Assessment table
feas_doc <- feas_doc %>% 
  body_add_flextable(case2_table, align = "left") %>%
  body_add_par(value = "")

# Add the final abuse determination for the initial assessment table
feas_doc <- feas_doc %>% 
  body_add_flextable(initial_tab, align = "left") %>%
  body_add_par(value = "")

# Add the final abuse determination for the secondary assessment table
feas_doc <- feas_doc %>% 
  body_add_flextable(sec_tab, align = "left") %>%
  body_add_par(value = "")

# Add the final abuse determination for the post-DETECT assessment table
feas_doc <- feas_doc %>% 
  body_add_flextable(post_tab, align = "left") %>%
  body_add_par(value = "")

# Add the percentage dissenting votes for each panelist discipline tables
feas_doc <- feas_doc %>%
  body_add_flextable(ini_diss, align = "left") %>%
  body_add_par(value = "") %>%
  body_add_flextable(sec_diss, align = "left") %>%
  body_add_par(value = "") %>%
  body_add_flextable(post_diss, align = "left") %>%
  body_add_par(value = "")

# print the word document
# print(feas_doc, target = "LEAD_data_metric_tables.docx")
```