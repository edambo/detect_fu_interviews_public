---
title: "LEAD Data Analysis"
format: html
---

# Load packages

```{r, warning=FALSE, echo=FALSE, output = FALSE, include=FALSE}
library(flextable)
library(table1)
library(dplyr)
library(tibble)
library(misty)
library(officer)
library(tidyverse)
library(readr)
library(purrr)
library(stringr)
library(mice)
library(lubridate)
library(writexl)
library(readxl)
```

# Load cleaned data

Load the participant, self report, LEAD panel assessment,LEAD panel meeting attendance, observational measures and sociodemographic information datasets

```{r}
#| warning: false
socio_demo <- readRDS("../data/cleaned_rds_files/sociodemographic_information_import.rds")
observational_measures <- readRDS("../data/cleaned_rds_files/observational_measures_import.rds")
lead_panel_assessment <- readRDS("../data/cleaned_rds_files/lead_panel_assessment_import.rds")
participant <- readr::read_rds("../data/cleaned_rds_files/participant_import.rds")
lead_attendance <- read_excel("../data/lead_panel_meeting_attendance_reports/Combined LEAD panel meeting attendance.xlsx")
```

# Data preparation

Prepare and then merge the relevant variables in the self report, LEAD panel assessment and sociodemographic information data sets into one data frame.

## Participant data

This data was collected by MedStar at the initial 911 response. It includes the results of the initial DETECT screening. We will need those screening results below to compare with LEAD panel findings. 

We will need the results of the DETECT tool filled out at the initial 911 call because we want to be able to say, "At the initial 911 response the DETECT tool was [positive/negtive] for EM. The lead panel then reviewed the case and determined that EM [was/was not] occuring. X porportion of the time, the initial DETECT screening and the LEAD panel determination agreed with each other."


```{r}
#| eval: false

# Look for duplicate by (MedStar ID) records
participant |> 
  group_by(medstar_id) |> 
  count() |> 
  filter(n > 1)

# 2023-08-01: No duplicate rows by MedStar ID
```

```{r}
# Keep only the columns of interest
parti <- participant |> 
  select(
    medstar_id, x_created_timestamp, x_record_month, x_record_year,
    incident_timestamp, unit_arrived_timestamp, complaint_reported,
    age, incident_result, symptom_list, xc_detect_positive_summary_count,
    x_caregiver_lack_knowledge_2cat_f:xc_detect_status_2cat_f
  )
```

## Sociodemographic Information

This data was collected during the DETECT follow-up interview. It includes participant sociodemographic information like race, household income and others. We will compare LEAD screening results across different sociodemographic categories. 

```{r}
# Select relevant variables of interest from sociodemographic information df
soc_dem <- socio_demo %>%
  select(medstar_id, sode_hispanic_4cat_f, sode_race : other, sode_income_9cat_f)

```

## MedStar Medic Assessment (Observational Measures Dataset)

This data comes from the DETECT follow-up interviews. It is a collection of medic EM responses to questions about whether or not they believe abuse has occurred based on provided definitions, signs and symptoms. We will compare these the Medic EM Assessment results to the LEAD Panel Assessment results.

```{r}
obs_meas <- observational_measures %>% 
  select(medstar_id, at_physical_4cat_f: at_self_4cat_f)
```

### Any positive determinations across all subtypes

Create a factor column 'medic_abuse_any' that indicates if an EM medic believes at least one type of abuse is present or none is present.

```{r}
obs_meas <- obs_meas %>%
  mutate(
    medic_abuse_any = case_when(
      if_any(at_physical_4cat_f : at_self_4cat_f, ~. == "Yes")  ~ 1,
      if_all(at_physical_4cat_f : at_self_4cat_f, ~. == "No")   ~ 0,
      TRUE                                                      ~ NA
    )
  )%>%
  mutate(
    medic_abuse_any = factor(
      medic_abuse_any,
      levels = c(0, 1),
      labels = c("No", "Yes")
    )
  )
```

## LEAD Panel Assessment

This data comes from participant abuse assessments by a Longitudinal, Experts, All Data (LEAD) panel. It will be analysed using variables in the sociodemographic, participant and observational measures datasets.

```{r}
# Select relevant variables from LEAD panel assessment df
lpa <- lead_panel_assessment %>%
  select(medstar_id, panelist_name_10cat_f, panelist_discipline, healthcare_worker, x_created_timestamp,x_assessment_month, x_assessment_year, assessment_type_3cat_f : xc_assessment_screened_2cat_f)
```

```{r}
# Subset with initial assessment only
initial_e <- lpa %>% filter(assessment_type_3cat_f == "Initial assessment")

# Subset with Secondary assessment only
secondary_e <- lpa %>% filter(assessment_type_3cat_f == "Secondary assessment")

# Subset with Post-detect assessment only
post_detect_e <- lpa %>% filter(assessment_type_3cat_f == "Post-detect assessment")
```

### ðŸ”´ Panelist multiple assessment data error

Look at medstar_id 47311d550da4471297501ae2b3b03b02. It looks like Jason completed two initial assessments, which shouldn't happen. My guess is that the second initial assessment should have been a secondary assessment and he accidentally clicked the wrong option in FM Pro. We could check this by:
1. Check to see if the there is already a secondary assessment for Jason for 47311d550da4471297501ae2b3b03b02.
2. Check the time stamp on the votes. The secondary assessment should come after the initial assessment (probably on a different day).
3. If there truly are multiple initial assessments, then we need to check if there is any difference between them. If not, then just keep the final row (in terms of time stamp).
4. If there ARE differences, this is trickier. I'm leaning towards keeping the final row here too, but we should look at some examples before making a final decision.

#### Identify Medstar IDs with data error

Create a function that identifies the specific issues and indicates whether a row should be excluded or not by adding the following columns:

_multiple_count_ - Indicate the number of rows for each panelist under each MedStar ID.

_same_score_     - For each MedStar ID, are all the scores assigned by the same panelist identical or different.

_over_24_hours_  - For each MedStar ID with multiple assessments for the same panelist, were the assessments performed within one day of each other?
_most_recent_    - For each MedStar ID with multiple assessments for the same panelist, was the entry for the specified row the most recent?

_all_na_         - Are all, some or none of the assessment values missing for the specified row?
_remove_         - Should this row be removed or is further review required to determine this based on the rules below?

                  1. Identical duplicates: Keep the most recent row.
                  2. Additional entries with all values missing : Remove rows with all missing vote values

```{r}
error_check <- function(assessment) {
  
  # Create a vector of abuse type columns. Will be used for grouping below.
  group <- c('physical_abuse_2cat', 'sexual_abuse_2cat', 'emotional_psycho_abuse_2cat', 'neglect_2cat', 
             'self_neglect_2cat', 'financial_exploitation_2cat', 'abandonment_2cat')
  
  # Add a column to the data frame -- multiple_count -- that is equal to the 
  # number of rows in the data frame for each combination of medstar ID and
  # panelist name.
  multiple_assessment <- assessment %>%
    group_by(medstar_id, panelist_name_10cat_f) %>% 
    mutate(
      multiple_count = length(panelist_name_10cat_f)
    ) %>%
    ungroup()
  
  # For each MedStar ID, are all the scores assigned by the same panelist identical or different (for each row, are there any other rows that are exactly the same in the group?).
  multiple_assessment <- multiple_assessment |> 
    group_by(
      medstar_id, panelist_name_10cat_f, sexual_abuse_2cat, emotional_psycho_abuse_2cat, neglect_2cat,
      self_neglect_2cat, financial_exploitation_2cat, abandonment_2cat
    ) %>%
    mutate(
      same_score = n() > 1
    ) %>%
    ungroup()
  
  # Are all, some. or none of the assessment values missing for the specified row?
  multiple_assessment <- multiple_assessment |> 
    mutate(
      all_na = case_when(
        if_all(all_of(group), ~ is.na(.))  ~ "all",
        if_all(all_of(group), ~ !is.na(.)) ~ "none",
        TRUE                               ~ "some"
      )
    ) %>%
    ungroup()
  
  # For each MedStar ID with multiple assessments for the same panelist, were 
  # the assessments performed within one day of each other?
  multiple_assessment <- multiple_assessment |>
    group_by(medstar_id, panelist_name_10cat_f) %>%
    mutate(
      over_24_hours = ifelse(
        (as.numeric(difftime(last(x_created_timestamp), first(x_created_timestamp), units = "hours")) > 24), 1, 0
      )
    )
  
  # For each MedStar ID with multiple assessments for the same panelist, was the entry for the specified row the most recent?
  multiple_assessment <- multiple_assessment |>
    mutate(
      most_recent = ifelse(x_created_timestamp == max(x_created_timestamp), "Yes", "No")
    )
  
  # Should this row be removed or is further review required to determine this 
  # based on the rules below?
  multiple_assessment <- multiple_assessment |>
    mutate(
      remove  = case_when(
        # Case when the error is present and the scores are not identical. All of the rows being compared have one or more missing
        # scores and at least one of the rows being compared does not have all of the scores missing. Marks such cases
        # for individual review
        multiple_count > 1 & same_score == FALSE & all(all_na != "none") & any(all_na != "all") ~ "Individual review",
        
        # Case when the error is present, the scores are not identical and at least one of the rows being compared has some but not all 
        # scores missing. Any of the other rows being compared could have none or all missing values. Marks such cases for
        # individual reveiw.
        multiple_count > 1 & same_score == FALSE & any(all_na == "some")                        ~ "Individual review",
        
        # Case when the error is present, the scores are not identical and all the rows being compared have no missing scores.
        multiple_count > 1 & same_score == FALSE & all(all_na == "none")                        ~ "Individual review",
        
        # case when there is no error
        multiple_count == 1                                                                     ~ "No",
        
        # Marks only the most recent of identical rows where error is present for keeping while the other rows are removed.
        multiple_count > 1 & same_score == TRUE & most_recent == "Yes"                          ~ "No",
        
        # Case when there is an error and the scores being compared are not the same. Marks rows where there are no missing scores
        # for keeping
        multiple_count > 1 & same_score == FALSE & all_na == "none"                             ~ "No",
       
        # Case when error is present but all the rows are identical in terms of assigned scores. Marks rows that are not the most
        # recent for removal
        multiple_count > 1 & same_score == TRUE & most_recent == "No"                           ~ "Yes",
       
        # Case when the error is present and the scores are not identical. Marks rows where all the scores are missing for removal
        multiple_count > 1 & same_score == FALSE & all_na == "all"                              ~ "Yes"
      )
    )
  
  # Return result
  multiple_assessment
}

# For testing
# error_check(initial_e) |> 
#   filter(multiple_count > 1)
```

```{r}
# Initial Assessments

initial_e <- error_check(initial_e)

initial_e %>% filter(multiple_count > 1) 
```

```{r}

# Secondary Assessments

secondary_e <- error_check(secondary_e)

secondary_e %>% filter(multiple_count > 1)
```

```{r}
# Post-detect assessments

post_detect_e <- error_check(post_detect_e)

post_detect_e %>% filter(multiple_count > 1)
```


### Create subsets for the 3 assessment types with the multiple assessment rows removed

Create a function that will remove the rows with issues.

```{r}
fix_error <- function(assessment) {
  # Remove rows marked by the error_check function for removal.
  assessment <-  assessment %>% filter(!(remove == "Yes")) 
  
  # Remove rows marked by the error_check function for individual review that are not the most recent.
  assessment <-  assessment %>% filter(!(remove == "Individual review" & most_recent == "No") | remove == "No") 
    
}

```

```{r}
# Initial assessment
initial <- fix_error(initial_e)

# Secondary assessment
secondary <- fix_error(secondary_e)

# Post-detect assessment
post_detect <- fix_error(post_detect_e)
```

### ðŸ”´ Create overall EM determination columns

For each medstar_id reviewed by the LEAD panel, we want to calculate:

1. Create a column containing the number of positive determinations at each assessment (initial, secondary, and post-DETECT) for each subtype of EM.

2. Create a column containing the proportion (denominator is number of non-missing votes) of positive determinations at each assessment (initial, secondary, and post-DETECT) for each subtype of EM.

### Total and proportion of positive votes for each Medstar iD

Create summary dataframes for each assessment that include calculated columns indicating the total number of positive votes and the proportion of positive votes for each MedStar ID.

#### Create a positive vote summary function that will be applied to each of the three assessment data frames.

```{r}
pos_votes <- function(assessment) {
  assessment %>% 
  group_by(medstar_id) %>% 
  reframe(
    # compute the sum of positive votes for each MedStar ID
    across(
      .cols  = c(physical_abuse_2cat : abandonment_2cat, xc_assessment_screened_2cat),
      .fns   = ~ sum(.x),
      .names = "{col}_t"
    ),
    assessment_type_3cat_f  = unique(assessment_type_3cat_f),
    # compute the proportion of positive votes for each MedStar ID
    across(
      .cols  = physical_abuse_2cat_t : xc_assessment_screened_2cat_t,
      .fns   = ~ case_when(
        .x   == 0  ~ 0,
        .x  !=  0  ~ .x/n()
      ),
      .names = "{col}_p"
    )
  ) %>%
  # rename the new columns
  rename_with(
    .cols   = ends_with("_t"), 
    .fn     = ~ gsub("2cat_t", "total", .x)
  ) %>% 
  rename_with(
    .cols   = ends_with("_p"), 
    .fn     = ~ gsub("2cat_t_p", "prop", .x)
  )
}
```

```{r}
# Initial Assessments

initial_pos_votes <- pos_votes(initial)
```

```{r}
# Secondary Assessments

secondary_pos_votes <- pos_votes(secondary)
```

```{r}
# Post-detect assessments

post_detect_pos_votes <- pos_votes(post_detect)
```

### Any positive determinations for each subtypes

3. Create a dichotomous variable that indicates if there were _any_ positive determinations at each assessment (initial, secondary, and post-DETECT) for each subtype of abuse.

```{r}
any_pos <- function(assessment_pos_votes) {
  assessment_pos_votes %>% 
    mutate(
      across(
        .cols   = physical_abuse_total : xc_assessment_screened_total,
        .fn     = ~ case_when(
          .x    == 0 ~ 0,
          .x    >  0 ~ 1
        ),
        .names  = "{col}_any"
      ),
      across(
        .cols   = ends_with("_any"),
        .fns    = ~ factor(.x, 
                      levels = c(0,1),
                      labels = c("No", "Yes")),
      .names = "{col}"
      )
    ) %>%
    rename_with(
      .cols   = ends_with("_any"), 
      .fn     = ~ gsub("total_any", "any", .x)
    )
  
}
```

```{r}
# Initial Assessments

initial_pos_votes <- any_pos(initial_pos_votes)
```

```{r}
# Secondary Assessments

secondary_pos_votes <- any_pos(secondary_pos_votes)
```

```{r}
# Post-detect assessments

post_detect_pos_votes <- any_pos(post_detect_pos_votes)
```

### Majority vote variable for each abuse type

Create columns that indicate the final LEAD Assessment determination based on majority vote. Final determination will be by majority (more than half) vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)

```{r}
final_det <- function(assessment_pos_votes) {
  assessment_pos_votes %>% 
    mutate(
      across(
        .cols   = physical_abuse_prop : xc_assessment_screened_prop,
        .fn     = ~ case_when(
          .x    <= 0.5         ~ 0,
          .x    >  0.5         ~ 1
        ),
        .names  = "{col}_det"
      ),
      across(
        .cols   = ends_with("_det"),
        .fns    = ~ factor(.x, 
                      levels = c(0,1),
                      labels = c("No", "Yes")),
      .names = "{col}"
      )
    ) %>%
    rename_with(
      .cols   = ends_with("_det"), 
      .fn     = ~ gsub("prop_det", "det", .x)
    )
}
```

```{r}
# Initial Assessments

initial_pos_votes <- final_det(initial_pos_votes)
```

```{r}
# Secondary Assessments

secondary_pos_votes <- final_det(secondary_pos_votes)
```

```{r}
# Post-detect assessments

post_detect_pos_votes <- final_det(post_detect_pos_votes)
```

### Any positive determinations across all subtypes

Create a dichotomous variable that indicates if there were _any_ positive determinations at each assessment (initial, secondary, and post-DETECT) across _all_ subtypes of EM.

```{r}
abuse_any <- function(assessment_final_det) {
  assessment_final_det %>%
    mutate(
      abuse_any = case_when(
        if_any(physical_abuse_det : abandonment_det, ~. == "Yes")  ~ 1,
        if_all(physical_abuse_det : abandonment_det, ~. == "No")   ~ 0,
        TRUE                                                       ~ NA
      )
    ) %>%
    mutate(
        abuse_any = factor(
        abuse_any,
        levels = c(0, 1),
        labels = c("No", "Yes")
      )
    )
}
```

```{r}
# Initial Assessments

initial_pos_votes <- abuse_any(initial_pos_votes)
```

```{r}
# Secondary Assessments

secondary_pos_votes <- abuse_any(secondary_pos_votes)
```

```{r}
# Post-detect assessments

post_detect_pos_votes <- abuse_any(post_detect_pos_votes)
```

```{r}
# Merge the initial_pos_votes and secondary_pos_votes data sets, keeping only the secondary_pos_votes for each medstar_id when it is available
final_determination <- initial_pos_votes[!initial_pos_votes$medstar_id %in% secondary_pos_votes$medstar_id,]
final_determination <- rbind(final_determination, secondary_pos_votes)
```

## Set labels

```{r}
# Overall final determination
label(final_determination$physical_abuse_det)         <- "LEAD physical abuse determination"
label(final_determination$sexual_abuse_det)           <- "LEAD sexual abuse determination"
label(final_determination$emotional_psycho_abuse_det) <- "LEAD emotional-psycho abuse determination"
label(final_determination$neglect_det)                <- "LEAD neglect determination"
label(final_determination$self_neglect_det)           <- "LEAD self-neglect determination"
label(final_determination$financial_exploitation_det) <- "LEAD financial exploitation determination"
label(final_determination$abandonment_det)            <- "LEAD abandonment determination"
label(final_determination$abuse_any)                  <- "LEAD any abuse determination"

# Initial positive votes
label(initial_pos_votes$physical_abuse_det)         <- "LEAD physical abuse determination"
label(initial_pos_votes$sexual_abuse_det)           <- "LEAD sexual abuse determination"
label(initial_pos_votes$emotional_psycho_abuse_det) <- "LEAD emotional-psycho abuse determination"
label(initial_pos_votes$neglect_det)                <- "LEAD neglect determination"
label(initial_pos_votes$self_neglect_det)           <- "LEAD self-neglect determination"
label(initial_pos_votes$financial_exploitation_det) <- "LEAD financial exploitation determination"
label(initial_pos_votes$abandonment_det)            <- "LEAD abandonment determination"
label(initial_pos_votes$abuse_any)                  <- "LEAD any abuse determination"

# Secondary positive votes
label(secondary_pos_votes$physical_abuse_det)         <- "LEAD physical abuse determination"
label(secondary_pos_votes$sexual_abuse_det)           <- "LEAD sexual abuse determination"
label(secondary_pos_votes$emotional_psycho_abuse_det) <- "LEAD emotional-psycho abuse determination"
label(secondary_pos_votes$neglect_det)                <- "LEAD neglect determination"
label(secondary_pos_votes$self_neglect_det)           <- "LEAD self-neglect determination"
label(secondary_pos_votes$financial_exploitation_det) <- "LEAD financial exploitation determination"
label(secondary_pos_votes$abandonment_det)            <- "LEAD abandonment determination"
label(secondary_pos_votes$abuse_any)                  <- "LEAD any abuse determination"

# Post-DETECT positive votes
label(post_detect_pos_votes$physical_abuse_det)         <- "LEAD physical abuse determination"
label(post_detect_pos_votes$sexual_abuse_det)           <- "LEAD sexual abuse determination"
label(post_detect_pos_votes$emotional_psycho_abuse_det) <- "LEAD emotional-psycho abuse determination"
label(post_detect_pos_votes$neglect_det)                <- "LEAD neglect determination"
label(post_detect_pos_votes$self_neglect_det)           <- "LEAD self-neglect determination"
label(post_detect_pos_votes$financial_exploitation_det) <- "LEAD financial exploitation determination"
label(post_detect_pos_votes$abandonment_det)            <- "LEAD abandonment determination"
label(post_detect_pos_votes$abuse_any)                  <- "LEAD any abuse determination"

# Socio-demographic variables
label(soc_dem$sode_hispanic_4cat_f)                      <- "Ethnicity (Hispanic)"
label(soc_dem$american_indian_or_alaska_native)          <- "American Indian or Alaska Native"
label(soc_dem$asian)                                     <- "Asian"
label(soc_dem$black_or_african_american)                 <- "Black or African American"
label(soc_dem$native_hawaiian_or_other_pacific_islander) <- "Native Hawaiian or Other Pacific Islander"
label(soc_dem$white)                                     <- "White"
label(soc_dem$other)                                     <- "Other"
label(soc_dem$sode_income_9cat_f)                        <- "Household Income"

# Observational measures variables
label(obs_meas$at_physical_4cat_f)   <- "Medic EM physical abuse assessment"
label(obs_meas$at_sexual_4cat_f)     <- "Medic EM sexual abuse assessment"
label(obs_meas$at_emotional_4cat_f)  <- "Medic EM emotional abuse assessment"
label(obs_meas$at_neglect_4cat_f)    <- "Medic EM neglect assessment"
label(obs_meas$at_abandon_4cat_f)    <- "Medic EM abandonment assessment"
label(obs_meas$at_financial_4cat_f)  <- "Medic EM financial abuse assessment"
label(obs_meas$at_self_4cat_f)       <- "Medic EM self-neglect assessment"
label(obs_meas$medic_abuse_any)      <- "Medic EM any abuse assessment"
label(parti$age)                     <- "Age (in years)"
label(parti$xc_detect_status_2cat_f) <- "Abuse determination at initial 911 call"
```

## Merge participant, observational measures, sociodemographic and LEAD dateframes

```{r}
# Merge subset dfs into a new df
final_determination <- purrr::reduce(list(final_determination, soc_dem, obs_meas, parti), dplyr::left_join, by = 'medstar_id')
final_det_initial   <- purrr::reduce(list(initial_pos_votes, soc_dem, obs_meas, parti), dplyr::left_join, by = 'medstar_id')
final_det_sec       <- purrr::reduce(list(secondary_pos_votes, soc_dem, obs_meas, parti), dplyr::left_join, by = 'medstar_id')
final_det_post      <- purrr::reduce(list(post_detect_pos_votes, soc_dem, obs_meas, parti), dplyr::left_join, by = 'medstar_id')
```

## Create dataframe containing "any abuse" determinations across the 3 assessments
This will be used to check the percent similarity of the final abuse determinations across the assessments.

```{r}
# Create a subset data frame with only the needed columns and rename columns to distinguish the initial assessment columns from those of the other assessments
initial_compare <- initial_pos_votes %>% 
  select(medstar_id, physical_abuse_det : abandonment_det, abuse_any) %>%
  rename(abuse_any_initial = abuse_any) %>%
    rename_with(
      .cols   = c(ends_with("_det")), 
      .fn     = ~ gsub("det", "det_init", .x)
    )

# Create a subset data frame with only the needed columns and rename columns to distinguish the secondary assessment columns from those of the other assessments
secondary_compare <- secondary_pos_votes %>% 
  select(medstar_id, physical_abuse_det : abandonment_det, abuse_any) %>%
  rename(abuse_any_sec = abuse_any) %>%
    rename_with(
      .cols   = c(ends_with("_det")), 
      .fn     = ~ gsub("det", "det_sec", .x)
    )

# Create a subset data frame with only the needed columns and rename columns to distinguish the post-DETECT assessment columns from those of the other assessments
post_compare <- post_detect_pos_votes %>% 
  select(medstar_id, physical_abuse_det : abandonment_det, abuse_any) %>%
  rename(abuse_any_post = abuse_any) %>%
    rename_with(
      .cols   = c(ends_with("_det")), 
      .fn     = ~ gsub("det", "det_post", .x)
    )

# Merge the above 3 data frames into one data frame
assessment_compare <- purrr::reduce(list(initial_compare, secondary_compare, post_compare), dplyr::left_join, by = 'medstar_id') %>%
  mutate(
    same_is = ifelse(is.na(abuse_any_sec), NA, 
      ifelse(abuse_any_initial == abuse_any_sec, 1,0)
      ),
    same_ip = ifelse(is.na(abuse_any_post), NA, 
                      ifelse(abuse_any_initial == abuse_any_post, 1,0)
    ),
    same_ii = ifelse(is.na(abuse_any_initial), NA, 
                      ifelse(abuse_any_initial == abuse_any_initial, 1,0)
    )
  )

```


## Participants interviewed between 05/2022 and 05/2023 with positive screening based on LEAD panel abuse determination 

This subset will be contacted for interviews for sharing their experiences.

```{r}
# Medic F/U assessment Medic abuse determination timestamp
med_time <- observational_measures %>% 
  select(medstar_id, x_created_timestamp)

# Add names from participant data frame since some are missing in the  LEAD assessment data frame. And include column showing participant's willingness to receive another phone call.
names <- participant %>% 
  select(medstar_id, name_full, x_do_not_call_2cat_f, phone)

# Add any_abuse variable from final_det_initial df.

abuse <- final_det_initial %>%
  select(medstar_id, abuse_any)

# Merge data sets and create participant list
interview_list <- purrr::reduce(list(abuse, names, med_time), dplyr::left_join, by = 'medstar_id') %>% 
  filter(
  as_date(x_created_timestamp) >= as_date("2022-05-01") & 
    as_date(x_created_timestamp) <= as_date("2023-05-31") &
    abuse_any == "Yes"
) %>% 
  select(medstar_id, name_full, x_created_timestamp, abuse_any, x_do_not_call_2cat_f, phone)

# Save list as an Excel sheet
# write_xlsx(interview_list, "interview_list.xlsx")
```

## LEAD panelist data metrics

Prepare the data to extract LEAD panel metric requested by Dr. Pickering.

### Paticipation of unique panelists per month across all assessment types

```{r}
# Merge the initial, secondary and post-DETECT datasets to create a dataset of all the LEAD data for selected variables excluding the rows with errors.
lead_cleaned <- purrr::reduce(list(initial, secondary, post_detect), rbind) %>% select(-c(multiple_count: remove))

# Create a date column combining month and year and including a placeholder value for day
lead_cleaned <- lead_cleaned %>%
  mutate(
    day = 1,
    x_assessment_month_num = dplyr::recode(x_assessment_month,
                                    January   = 1,
                                    February  = 2,
                                    March     = 3,
                                    April     = 4,
                                    May       = 5,
                                    June      = 6,
                                    July      = 7,
                                    August    = 8,
                                    September = 9,
                                    October   = 10,
                                    November  = 11,
                                    December  = 12
    )
  ) %>% 
  mutate(
    assessment_date = make_date(year  = x_assessment_year,
                                month = x_assessment_month_num, day = day)
  )

# Create a data frame containing only the participation dates and names of unique panelists
panelist_participation <- lead_cleaned %>% 
  group_by(assessment_date) %>%
  reframe(
    unique_panelist = unique(panelist_name_10cat_f),
    attendance = length(unique(panelist_name_10cat_f))
  )
# Create a data frame that shows the number of unique panelists per month that participated in LEAD meetings
unique_panelist_participation <- panelist_participation %>% 
  select(assessment_date, attendance) %>% unique()
```

### Average meeting attendance

Average meeting attendance is the number of unique people who filled out a secondary assessment each month.

```{r}
# Create a dataframe containing only the months and names of unique panelists that voted in the secondary assessment.
sec_meeting_attendance <- lead_cleaned %>%
  filter(assessment_type_3cat_f == "Secondary assessment") %>%
  group_by(assessment_date) %>%
  reframe(
    unique_panelist = unique(panelist_name_10cat_f),
    attendance = length(unique(panelist_name_10cat_f))
  )

unique_secondary_attendance <- sec_meeting_attendance %>% 
  select(assessment_date, attendance) %>% unique()
```

### Average meeting length from 7/22/2020 to 5/24/2023

```{r}
# Create meeting_date column and re-format attendance_duration variable as numerical
lead_attendance <- lead_attendance %>% 
  mutate(
    meeting_date        = as_date(meeting_start_time),
    attendance_duration_mins = as.numeric(gsub(" min.*", "", attendance_duration)
                                     )
    )


# Find average meeting length using the longest attendance duration per date. 
meeting_duration <- lead_attendance %>% group_by(meeting_date) %>% 
  reframe(
    meeting_time = max(attendance_duration_mins)
  )
```

### Unique panelists per assessment type

Create data frames to extract information on the unique panelists that voted in each assessment and across all assessments. 

```{r}
initial_panelists     <- initial %>% ungroup() %>% select(panelist_name_10cat_f) %>% unique()
secondary_panelists   <- secondary %>% ungroup() %>% select(panelist_name_10cat_f) %>% unique() 
post_panelists        <- post_detect %>% ungroup() %>% select(panelist_name_10cat_f) %>% unique() 
```

# Analaysis

## Missing data summary

```{r, fig.width = 20}
fd_m <- final_determination %>% 
  select(
    physical_abuse_det: at_self_4cat_f,  
    )%>% md.pattern(., plot = T, rotate.names = T)
```

## Number and proportion of assessements completed by type of assesement

How many unique MedStar IDs went to the LEAD panel for review?

```{r, include=FALSE}
unique_medstar_ids <- unique(lpa$medstar_id) |> length()
cat("Unique MedStar ID's =", unique_medstar_ids)
```

### Initial assessment

```{r, include=FALSE}
unique_medstar_ids_initial <- unique(initial$medstar_id) |> length()
cat("Unique MedStar ID's at intitial assessment =", unique_medstar_ids_initial)
```

```{r, include=FALSE}
cat("Proportion of MedStar ID's with an intitial assessment =", unique_medstar_ids_initial/unique_medstar_ids)
```

### Secondary assessment

```{r, include=FALSE}
unique_medstar_ids_secondary <- unique(secondary$medstar_id) |> length()
cat("Unique MedStar ID's at secondary assessment =", unique_medstar_ids_secondary)
```

```{r, include=FALSE}
cat("Proportion of MedStar ID's with an secondary assessment =", unique_medstar_ids_secondary/unique_medstar_ids)
```

### Post-DETECT assessment

```{r, include=FALSE}
unique_medstar_ids_post_detect <- unique(post_detect$medstar_id) |> length()
cat("Unique MedStar ID's at post-DETECT assessment =", unique_medstar_ids_post_detect)
```

```{r, include=FALSE}
cat("Proportion of MedStar ID's with an post-DETECT assessment =", unique_medstar_ids_post_detect/unique_medstar_ids)
```

### Summary table
```{r}
sum_table <- data.frame(
                        Value = c("Unique MedStar ID's at initial assessment", 
                                  "Unique MedStar ID's at secondary assessment", 
                                  "Unique MedStar ID's at post-DETECT assessment", 
                                  "Total unique MedStar ID's across all assessments"),
                        Count = c(unique_medstar_ids_initial, unique_medstar_ids_secondary,
                                  unique_medstar_ids_post_detect, unique_medstar_ids),
                        Proportion = c((unique_medstar_ids_initial/unique_medstar_ids), 
                                       (unique_medstar_ids_secondary/unique_medstar_ids), 
                                       (unique_medstar_ids_post_detect/unique_medstar_ids), 
                                       1)
                        ) %>%
  mutate(
    Proportion = format(round(Proportion, digits = 4), nsmall = 4)
    )%>%
  flextable()
# Set caption

sum_table <- set_caption(sum_table, "Summary of Unique Medstar IDs for the LEAD Assessment Data")
sum_table <- width(sum_table, width = 1.5)


sum_table
```

## Percent Similarity of determinations between the different assessments

Create a table that shows the percent similarity between each of the three assessment types and each of the other types using the dataframe containing "any abuse" determination across the 3 assessments. 

Answers the question: When comparing the one assessment type to the other, what is the percentage of determinations that were the same in another assessment type, using the the smaller variable as the denominator?

### Function
This function takes the name of a variable in the assessment_compare df that indicates whether or not the abuse determinations are the same for specified variables as an input. It computes the percent of abuse determinations that are the same rounded to 2 decimal places.  
```{r}
similarity <- function(column){
  round(length(which(assessment_compare[[column]] == 1))/length(which(!is.na(assessment_compare[[column]]) == TRUE))*100, digits = 2)  
}
```

### Values
```{r}
# Create values for the table
ii = similarity("same_ii")
is = similarity("same_is")
ip = similarity("same_ip")
```

### Format table
```{r}
sim_table <- data.frame(
                        Value = c("Initial", "Secondary", "Post-DETECT"),
                        Initial     = c(ii, is, ip) 
                        ) %>%
  flextable()
# Set caption
sim_table <- set_caption(sim_table, "Table Showing the Percent Similarity Between the Initial Assessment Determination and the Other Assessment Types")

# format line
std_border = fp_border(color="black")

# Set header labels 

sim_table <- set_header_labels(sim_table, Value = "")
sim_table <- set_header_labels(sim_table, Post_detect = "Post-DETECT")

sim_table <- width(sim_table, width = 2)
sim_table <- vline(sim_table, j = 1, border = std_border)

sim_table
```

## LEAD data metrics requested by Dr. Pickering

### Metrics

I understand people could vote 3 times as they got additional information/discussion -- how many people did that? interpreted as: How many LEAD panelists voted in all three assessments (initial, secondary, post-detect)

```{r}
voted_in_all <- Reduce(intersect, list(initial_panelists, secondary_panelists, post_panelists)) %>% nrow()
cat("Total number of unique panelists that voted in all three assessments =", voted_in_all)
```
The number of unique panelists that voted in the initial assessment

```{r}
initial_voters <- initial_panelists %>% nrow()
cat("Number of unique panelists that voted in the initial assessment =", initial_voters)
```
The number of unique panelists that voted in the secondary assessment

```{r}
secondary_voters <- secondary_panelists %>% nrow()
cat("Number of unique panelists that voted in the secondary assessment =", secondary_voters)
```

The number of unique panelists that voted in the post-DETECTl assessment

```{r}
post_voters <- post_panelists %>% nrow()
cat("Number of unique panelists that voted in the post-DETECT assessment =", post_voters)
```

The number of people who were asked to be on LEAD and the number who agreed. Everyone who was asked agreed.  

```{r}
all_voters <- Reduce(union, list(initial_panelists, secondary_panelists, post_panelists)) %>% nrow()
cat("Total number of unique panelists across all three assessments =", all_voters)
```

Average meeting attendance. The average meeting attendance is the number of unique people who filled out a secondary assessment each month.

```{r}
cat("Average meeting attendance =", mean(unique_secondary_attendance$attendance))
```
Average meeting length from 7/22/2020 to 5/24/2023

```{r}
cat("Average meeting length =", mean(meeting_duration$meeting_time))
```

### Plot
Create a plot that shows the number of unique panelists that participated per month over time.

```{r}
participation <- ggplot(aes(x = assessment_date, y = attendance), data = unique_panelist_participation) + geom_line() +
  labs(title = "Number of Unique Panelists Per Month Over Time ", x = "Time", 
       y = "Number of Unique Panelists Per Month")

participation

ggsave("participation_plot.png")
```

### Abuse types of the dissimilar cases
For the cases that did not have congruence â€“ what type of cases were they? (physical, self-neglect, etc)

#### Initial vs Secondary

##### Create dummy variables that indicate the type of case 

```{r}
# Dissimilar cases between the initial and secondary assessments
sec_dissimilar <- assessment_compare %>% filter(same_is == 0) %>% select(-c(same_ip, same_ii, ends_with("_post")))
```

```{r}
sec_dissimilar <- sec_dissimilar %>% 
  mutate(
    non_con_phys = ifelse(physical_abuse_det_init != physical_abuse_det_sec, 1, 0),
    non_con_sex  = ifelse(sexual_abuse_det_init != sexual_abuse_det_sec, 1, 0),
    non_con_emo  = ifelse(emotional_psycho_abuse_det_init != emotional_psycho_abuse_det_sec, 1, 0),
    non_con_neg  = ifelse(neglect_det_init != neglect_det_sec, 1, 0),
    non_con_self = ifelse(self_neglect_det_init != self_neglect_det_sec, 1, 0),
    non_con_fin  = ifelse(financial_exploitation_det_init != financial_exploitation_det_sec, 1, 0),
    non_con_aban = ifelse(abandonment_det_init != abandonment_det_sec, 1, 0),
    total        = rowSums(
      across(
        .cols = non_con_phys : non_con_aban
      )
    )
  )
```

##### Values
```{r}
# Create values for the table
phys = sec_dissimilar %>% filter(non_con_phys == 1) %>% nrow()
sex = sec_dissimilar %>% filter(non_con_sex == 1) %>% nrow()
emo = sec_dissimilar %>% filter(non_con_emo == 1) %>% nrow()
neg = sec_dissimilar %>% filter(non_con_neg == 1) %>% nrow()
self = sec_dissimilar %>% filter(non_con_self == 1) %>% nrow()
fin = sec_dissimilar %>% filter(non_con_fin == 1) %>% nrow()
aban = sec_dissimilar %>% filter(non_con_aban == 1) %>% nrow()
```

##### Format table
```{r}
case_table <- data.frame(
                        Value = c("Physical abuse", "Sexual abuse", "Emotional abuse", "Neglect",
                                  "Self-neglect", "Financial abuse","Abandonment"),
                        Count     = c(phys, sex, emo, neg, self, fin, aban),
                        Proportion = c(phys/21, sex/21, emo/21, neg/21, self/21, fin/21, aban/21)
                        ) %>%
  flextable()
# Set caption
case_table <- set_caption(case_table, "Non-congruent Cases Between Initial Assessment Determination and Secondary Assessment (Total non-congruent cases = 21)")


# Set header labels 

case_table <- set_header_labels(case_table, Value = "Abuse Types")

case_table <- width(case_table, width = 2)

case_table <- add_footer_lines(case_table, values = c("In one case, 2 types of abuse (emotional and financial) were detected simultaneously."))

case_table <- italic(case_table, italic = TRUE, part = "footer")

case_table

```

#### Initial vs Post-DETECT

##### Create dummy variables that indicate the type of case 

```{r}
# Dissimilar cases between the initial and secondary assessments
post_dissimilar <- assessment_compare %>% filter(same_ip == 0) %>% select(-c(same_is, same_ii, ends_with("_sec")))
```

```{r}
post_dissimilar <- post_dissimilar %>% 
  mutate(
    non_con_phys = ifelse(physical_abuse_det_init != physical_abuse_det_post, 1, 0),
    non_con_sex  = ifelse(sexual_abuse_det_init != sexual_abuse_det_post, 1, 0),
    non_con_emo  = ifelse(emotional_psycho_abuse_det_init != emotional_psycho_abuse_det_post, 1, 0),
    non_con_neg  = ifelse(neglect_det_init != neglect_det_post, 1, 0),
    non_con_self = ifelse(self_neglect_det_init != self_neglect_det_post, 1, 0),
    non_con_fin  = ifelse(financial_exploitation_det_init != financial_exploitation_det_post, 1, 0),
    non_con_aban = ifelse(abandonment_det_init != abandonment_det_post, 1, 0),
    total        = rowSums(
      across(
        .cols = non_con_phys : non_con_aban
      )
    )
  )
```

##### Values
```{r}
# Create values for the table
phys2 = post_dissimilar %>% filter(non_con_phys == 1) %>% nrow()
sex2 = post_dissimilar %>% filter(non_con_sex == 1) %>% nrow()
emo2 = post_dissimilar %>% filter(non_con_emo == 1) %>% nrow()
neg2 = post_dissimilar %>% filter(non_con_neg == 1) %>% nrow()
self2 = post_dissimilar %>% filter(non_con_self == 1) %>% nrow()
fin2 = post_dissimilar %>% filter(non_con_fin == 1) %>% nrow()
aban2 = post_dissimilar %>% filter(non_con_aban == 1) %>% nrow()
```

##### Format table
```{r}
case2_table <- data.frame(
                        Value = c("Physical abuse", "Sexual abuse", "Emotional abuse", "Neglect",
                                  "Self-neglect", "Financial abuse","Abandonment"),
                        Count     = c(phys2, sex2, emo2, neg2, self2, fin2, aban2),
                        Proportion = c(phys2/12, sex2/12, emo2/12, neg2/12, self2/12, fin2/12, aban2/12)
                        ) %>%
  flextable()
# Set caption
case2_table <- set_caption(case2_table, "Non-congruent Cases Between Initial Assessment Determination and Post-DETECT Assessment (Total non-congruent cases = 12)")


# Set header labels 

case2_table <- set_header_labels(case2_table, Value = "Abuse Types")

case2_table <- width(case2_table, width = 2)

case2_table
```

### LEAD Panelist Votes

For each LEAD panel member, how many initial votes did they have? How many secondary votes did they have? How often did their initial vote change at the secondary vote?


#### Prepare the data
```{r}
init_sec <- lead_cleaned %>%
  # Select only the needed columns
  select(c(medstar_id, assessment_type_3cat_f, panelist_name_10cat_f, physical_abuse_2cat : abandonment_2cat))

# Create a subset data frame with only the initial assessment rows and rename the abuse columns to distinguish them from those of the secondary assessment
initial_panelist_votes <- init_sec %>%
  filter(assessment_type_3cat_f ==  "Initial assessment") %>%
  select(-c(assessment_type_3cat_f)) %>%
  rename_with(
    .cols   = c(ends_with("_2cat")), 
    .fn     = ~ gsub("2cat", "2cat_init", .x)
  )

# Create a subset data frame with only the secondary assessment rows and rename the abuse columns to distinguish them from those of the initial assessment
sec_panelist_votes <- init_sec %>%
  filter(assessment_type_3cat_f ==  "Secondary assessment") %>%
  select(-c(assessment_type_3cat_f)) %>%
  rename_with(
    .cols   = c(ends_with("_2cat")), 
    .fn     = ~ gsub("2cat", "2cat_sec", .x)
  )

# Merge the two above data frames into one
panelist_votes <- purrr::reduce(list(sec_panelist_votes, initial_panelist_votes), dplyr::left_join, 
                                by = c('medstar_id', "panelist_name_10cat_f"))

# Create columns that compare the secondary and initial vote for each abuse type
panelist_votes<- panelist_votes %>%
  mutate(
    phys_agree = ifelse(physical_abuse_2cat_sec == physical_abuse_2cat_init, 1, 0),
    sex_agree = ifelse(sexual_abuse_2cat_sec == sexual_abuse_2cat_init, 1, 0),
    emo_agree = ifelse(emotional_psycho_abuse_2cat_sec == emotional_psycho_abuse_2cat_init, 1, 0),
    neg_agree = ifelse(neglect_2cat_sec == neglect_2cat_init, 1, 0),
    self_agree = ifelse(self_neglect_2cat_sec == self_neglect_2cat_init, 1, 0),
    fin_agree = ifelse(financial_exploitation_2cat_sec == financial_exploitation_2cat_init, 1, 0),
    aban_agree = ifelse(abandonment_2cat_sec == abandonment_2cat_init, 1, 0)
  )
```

#### Create the dataframe

```{r}
type_perc_change <- function(a_agree, a_type) {
  # Create data frame that will be used to compute the vote change frequency per abuse type for each panelist
  tab1 <- as.data.frame(addmargins(table(panelist_votes$panelist_name_10cat_f, panelist_votes[[a_agree]]), c(2)))
    
  # Make the data frames tidy
  df1 <- tab1 %>%
    pivot_wider(names_from = Var2, values_from = Freq) %>%
    rename(panelist_name = Var1, 
          n_votes = Sum,
          n_changed_votes = "0") %>%
    select(-c("1")) %>%
    #mutate(
      # create column for the percentage of votes that were changed from the initial to secondary assessment
      #perc_changed = paste0(format(round((n_changed_votes/n_votes)*100, digits = 2), nsmall = 2), " %")
    #) %>%
    #select(-c(n_votes, n_changed_votes)) %>%
    mutate(
      abuse_type = a_type
    )
    
  # Create data frame containing the number of initial and secondary votes per abuse type for each panelist
  tab2 <- as.data.frame(table(lead_cleaned$panelist_name_10cat_f, lead_cleaned$assessment_type_3cat_f,
                              lead_cleaned$physical_abuse_2cat))

  # Make the data frames tidy
  df2 <- tab2 %>%
    pivot_wider(names_from = Var3, values_from = Freq) %>%
    rename(yes = "1",
          no = "0") %>%
    mutate(n_votes = yes + no) %>%
    select(-c(yes, no)) %>%
    pivot_wider(names_from = Var2, values_from = n_votes) %>%
    select(-c("Post-detect assessment")) %>%
    rename(panelist_name = Var1, 
          initial_n_votes = "Initial assessment",
          sec_n_votes = "Secondary assessment")

  # Merge the percent changed vote and vote count per assessment data frames
  comb_df <- left_join(df2, df1, by = "panelist_name")
}

# Physical abuse
phys_disc <- type_perc_change("phys_agree", "Physical Abuse")
  
# Sexual abuse
sex_disc <- type_perc_change("sex_agree", "Sexual Abuse")
  
# Emotional-psychological abuse
emo_disc <- type_perc_change("emo_agree", "Emotional-Psychological Abuse")

# Neglect
neg_disc <- type_perc_change("neg_agree", "Neglect")
  
# Self-neglect
self_disc <- type_perc_change("self_agree", "Self-neglect")
  
# Financial Explotation
fin_disc <- type_perc_change("fin_agree", "Financial Exploitation")
  
# Abandonment
aban_disc <- type_perc_change("aban_agree", "Abandonment")
  
# Merge dataframes for each abuse type to create one data frame for all abuse types
panelist_vote_sum <- purrr::reduce(list(phys_disc, sex_disc, emo_disc, neg_disc, self_disc, fin_disc, aban_disc), rbind)
  
# Compute "Overall" rows for each panelist from sum of votes and dissenting votes for all the abuse types 
panelist_vote_sum <- panelist_vote_sum %>%
group_by(panelist_name) %>%
bind_rows(
  reframe(
    .,
    across(
      .cols = c(initial_n_votes, sec_n_votes, n_changed_votes, n_votes),
      .fns  = ~sum(.x)
    ),
    abuse_type = "Overall",
    panelist_name = panelist_name
  )
) %>%
distinct()
  
# Replace the vote count per abuse type and the number of changed votes columns with a column that shows the number of changed votes as a percentage of the vote count per abuse type
panelist_vote_sum <- panelist_vote_sum %>%
  mutate(
    # create column for the percentage of votes that were changed from the initial to secondary assessment
    perc_changed = paste0(format(round((n_changed_votes/n_votes)*100, digits = 2), nsmall = 2), " %")
  ) %>%
    select(-c(n_votes, n_changed_votes)) %>%
  # remove "%" after "NaN"
  mutate(perc_changed = str_replace(perc_changed, "NaN %", "NaN"))
```

#### Format the table

```{r}
# Set border formatting
std_border = fp_border(color="black")

# Convert the data frame into a flextable that groups the data by abuse type
pan_vote <- as_grouped_data(panelist_vote_sum, groups = "abuse_type") %>%
  as_flextable(hide_grouplabel = TRUE) %>%
  
  # Set the table caption
  set_caption("Initial and Secondary Assessment Vote Counts for Each LEAD Panelist and Percentage of Initial Votes that Changed at the Secondary Assessment for Cases that were Voted on In Both Assessments") %>%
  
  # Set table borders
  surround(i = ~ !is.na(abuse_type),
           border = std_border) %>%
  border_outer(part="all", border = std_border) %>%
  vline(border = std_border ) %>%
  
  # Rename and format the header labels
  set_header_labels(panelist_name   = "Panelist Name",
                    initial_n_votes = "N Initial Votes",
                    sec_n_votes     = "N Seconday Votes",
                    perc_changed     = "Percentage of Changed Votes") %>%
  bold(bold = TRUE, part="header") %>%
  
  # Adjust the table width
  width(width = 1.5)

pan_vote

```

### Panelist Disciplines of Non-Congruent Cases

For cases that did not have congruence (or at least initially) â€“ were there certain disciplines that tended to diverge from the others?


#### Function

Create a function that generates variables that indicate whether or not each vote for each case agrees with other votes for the same case.

The MedStar IDs that did not have voter congruence are identified by comparing the number of observations when the data is grouped by medstar_id and the abuse columns to when the data is only grouped by medstar_id.

```{r}
panelist_vote_agreement <- function(assessment){
  lead_cleaned %>% filter(assessment_type_3cat_f == assessment) %>%
    
    # Create variable that indicates for each row within each case, how many rows in total have that exact same voting pattern across all abuse types.
    group_by(
      medstar_id, physical_abuse_2cat, sexual_abuse_2cat, emotional_psycho_abuse_2cat, neglect_2cat,
      self_neglect_2cat, financial_exploitation_2cat, abandonment_2cat
    ) %>%
    mutate(
      identical_all_length = n()
    ) %>%
    ungroup() %>%
    # Create a variable that indicates the number of total voters per MedStar ID
    group_by(medstar_id) %>%
    mutate(
      voter_length = n() 
    )%>%
    # Create a variable that indicates whether or not there is 100% congruence in votes for each case.
    mutate(
      congruent_votes = case_when(
        identical_all_length == voter_length  ~ 1,
        identical_all_length != voter_length  ~ 0
      )
    ) %>%
    
    # Create a variable that indicates for each row within each case, how many total rows contain the same physical abuse vote.
    group_by(medstar_id, physical_abuse_2cat) %>%
    mutate(
      identical_phys_length = n() 
    )%>%
    ungroup() %>%
    # Create a variable that indicates whether or not each physical abuse vote is in agreement with half or more of all the votes for each case.
    mutate(
      phys_agree = case_when(
        identical_phys_length >= 0.5*voter_length  ~ 1,
        identical_phys_length < 0.5*voter_length  ~ 0
      )
    ) %>% 
    
    # Create a variable that indicates for each row within each case, how many total rows contain the same sexual abuse vote.
    group_by(medstar_id, sexual_abuse_2cat) %>%
    mutate(
      identical_sex_length = n() 
    )%>%
    ungroup() %>%
    # Create a variable that indicates whether or not each sexual abuse vote is in agreement with half or more of all the votes for each case.
    mutate(
      sex_agree = case_when(
        identical_sex_length >= 0.5*voter_length  ~ 1,
        identical_sex_length < 0.5*voter_length  ~ 0
      )
    ) %>% 
    
    # Create a variable that indicates for each row within each case, how many total rows contain the same emotional-psychological abuse vote.
    group_by(medstar_id, emotional_psycho_abuse_2cat) %>%
    mutate(
      identical_emo_length = n() 
    )%>%
    ungroup() %>%
    # Create a variable that indicates whether or not each emotional-psychological abuse vote is in agreement with half or more of all the votes for each case.
    mutate(
      emo_agree = case_when(
        identical_emo_length >= 0.5*voter_length  ~ 1,
        identical_emo_length < 0.5*voter_length  ~ 0
      )
    ) %>% 
    
    # Create a variable that indicates for each row within each case, how many total rows contain the same neglect abuse vote.
    group_by(medstar_id, neglect_2cat) %>%
    mutate(
      identical_neg_length = n() 
    )%>%
    ungroup() %>%
    # Create a variable that indicates whether or not each neglect vote is in agreement with half or more of all the votes for each case.
    mutate(
      neg_agree = case_when(
        identical_neg_length >= 0.5*voter_length  ~ 1,
        identical_neg_length < 0.5*voter_length  ~ 0
      )
    ) %>% 
    
    # Create a variable that indicates for each row within each case, how many total rows contain the same self-neglect vote.
    group_by(medstar_id, self_neglect_2cat) %>%
    mutate(
      identical_self_length = n() 
    )%>%
    ungroup() %>%
    # Create a variable that indicates whether or not each self-neglect vote is in agreement with half or more of all the votes for each case.
    mutate(
      self_agree = case_when(
        identical_self_length >= 0.5*voter_length  ~ 1,
        identical_self_length < 0.5*voter_length  ~ 0
      )
    ) %>% 
    
    # Create a variable that indicates for each row within each case, how many total rows contain the same financial abuse vote.
    group_by(medstar_id, financial_exploitation_2cat) %>%
    mutate(
      identical_fin_length = n() 
    )%>%
    ungroup() %>%
    # Create a variable that indicates whether or not each financial exploitation vote is in agreement with half or more of all the votes for each case.
    mutate(
      fin_agree = case_when(
        identical_fin_length >= 0.5*voter_length  ~ 1,
        identical_fin_length < 0.5*voter_length  ~ 0
      )
    ) %>%
    
    # Create a variable that indicates for each row within each case, how many total rows contain the same financial abuse vote.
    group_by(medstar_id, abandonment_2cat) %>%
    mutate(
      identical_aban_length = n() 
    )%>%
    ungroup() %>%
    # Create a variable that indicates whether or not each abandonment vote is in agreement with half or more of all the votes for each case.
    mutate(
      aban_agree = case_when(
        identical_aban_length >= 0.5*voter_length  ~ 1,
        identical_aban_length < 0.5*voter_length  ~ 0
      )
    )
}
```

#### Apply function to the different assessment types
```{r}

# Initial assessment
initial_vote_agreement <- panelist_vote_agreement("Initial assessment")

# Secondary assessment
secondary_vote_agreement <- panelist_vote_agreement("Secondary assessment")

# Post-DETECT assessment
post_vote_agreement <- panelist_vote_agreement("Post-detect assessment")
```

#### LEAD Panel Disciple Tables Showing Dissenting Votes by Panelist Discipline and Abuse Type
##### Create summary data frames

Create a function that will generate a summary dataframe for each assessment type containing the vote counts for each panelist discipline under each abuse type as well as the overall vote counts for each discipline across all abuse types.
```{r}
summary_vote_agreement <- function(assessment_vote_agreement) {
  
  discipline_vote_agreement <- function(abuse_agree, a_type) {
    # Create frequency tables with the panelist discipline and each abuse agreement variables. Convert tables to data frames
    tab <- as.data.frame(addmargins(table(assessment_vote_agreement$panelist_discipline, assessment_vote_agreement[[abuse_agree]]), c(2)))
    
    # Make data frames tidy
    df <- tab %>%
      pivot_wider(names_from = Var2, values_from = Freq) %>%
      rename(panelist_discipline = Var1, 
             n_votes = Sum,
             n_dissenting_votes = "0") %>%
      select(-c("1")) %>%
      mutate(
        abuse_type = a_type
      )
  }
  
  # Physical abuse
  phys_disc <- discipline_vote_agreement("phys_agree", "Physical Abuse")
  
  # Sexual abuse
  sex_disc <- discipline_vote_agreement("sex_agree", "Sexual Abuse")
  
  # Emotional-psychological abuse
  emo_disc <- discipline_vote_agreement("emo_agree", "Emotional-Psychological Abuse")
  
  # Neglect
  neg_disc <- discipline_vote_agreement("neg_agree", "Neglect")
  
  # Self-neglect
  self_disc <- discipline_vote_agreement("self_agree", "Self-neglect")
  
  # Financial Explotation
  fin_disc <- discipline_vote_agreement("fin_agree", "Financial Exploitation")
  
  # Abandonment
  aban_disc <- discipline_vote_agreement("aban_agree", "Abandonment")
  
  # Merge dataframes for each abuse type to create one data frame for all abuse types
  discipline_agree <- purrr::reduce(list(phys_disc, sex_disc, emo_disc, neg_disc, self_disc, fin_disc, aban_disc), rbind)
  
  # Compute "Overall" rows for each panelist discipline from sum of votes and dissenting votes for all the abuse types 
  discipline_agree <- discipline_agree %>%
  group_by(panelist_discipline) %>%
  bind_rows(
    reframe(
      .,
      across(
        .cols = c(n_dissenting_votes, n_votes),
        .fns  = ~sum(.x)
      ),
      abuse_type = "Overall",
      panelist_discipline = panelist_discipline
    )
  ) %>%
  distinct()
  
  # Replace dissenting votes column with a column that shows dissenting vote count and percentage over the number of votes
  discipline_agree <- discipline_agree %>%
  mutate(
    n_perc_diss_votes = paste0(n_dissenting_votes, " (", format(round((n_dissenting_votes/ n_votes)*100, digits = 4),nsmall = 4), "%)")
  ) %>%
    select(-c(n_dissenting_votes))
}
```

##### Apply function to the different assessment types
```{r}

# Initial assessment
initial_vote_agreement_sum <- summary_vote_agreement(initial_vote_agreement)

# Secondary assessment
secondary_vote_agreement_sum <- summary_vote_agreement(initial_vote_agreement)

# Post-DETECT assessment
post_vote_agreement_sum <- summary_vote_agreement(post_vote_agreement)
```

##### Create formated tables

###### Initial Assessment
```{r}
# Set border formatting
std_border = fp_border(color="black")

# Convert the vote agreement summary df into a flextable that groups the data by abuse type
ini_diss <- as_grouped_data(initial_vote_agreement_sum, groups = "abuse_type") %>%
  as_flextable(hide_grouplabel = TRUE) %>%
  
  # Set the table caption
  set_caption("Percent of Dissenting Votes for Each Panelist Discipline in the Initial Assessment") %>%
  
  # Set table borders
  surround(i = ~ !is.na(abuse_type),
           border = std_border) %>%
  border_outer(part="all", border = std_border) %>%
  vline(border = std_border ) %>%
  
  # Rename and format the header labels
  set_header_labels(panelist_discipline = "Panelist Discipline",
                    n_votes             = "N Secondary Votes",
                    n_perc_diss_votes   = "N (%) dissenting votes") %>%
  bold(bold = TRUE, part="header") %>%
  
  # Adjust the table width
  width(width = 2)

ini_diss
```

###### Secondary Assessment
```{r}
# Set border formatting
std_border = fp_border(color="black")

# Convert the vote agreement summary df into a flextable that groups the data by abuse type
sec_diss <- as_grouped_data(secondary_vote_agreement_sum, groups = "abuse_type") %>%
  as_flextable(hide_grouplabel = TRUE) %>%
  
  # Set the table caption
  set_caption("Percent of Dissenting Votes for Each Panelist Discipline in the Secondary Assessment") %>%
  
  # Set table borders
  surround(i = ~ !is.na(abuse_type),
           border = std_border) %>%
  border_outer(part="all", border = std_border) %>%
  vline(border = std_border ) %>%
  
  # Rename and format the header labels
  set_header_labels(panelist_discipline = "Panelist Discipline",
                    n_votes             = "N Post-DETECT Votes",
                    n_perc_diss_votes   = "N (%) dissenting votes") %>%
  bold(bold = TRUE, part="header") %>%
  
  # Adjust the table width
  width(width = 2)

sec_diss
```

###### Post-DETECT Assessment
```{r}
# Set border formatting
std_border = fp_border(color="black")

# Convert the vote agreement summary df into a flextable that groups the data by abuse type
post_diss <- as_grouped_data(post_vote_agreement_sum, groups = "abuse_type") %>%
  as_flextable(hide_grouplabel = TRUE) %>%
  
  # Set the table caption
  set_caption("Percent of Dissenting Votes for Each Panelist Discipline in the Post-DETECT Assessment") %>%
  
  # Set table borders
  surround(i = ~ !is.na(abuse_type),
           border = std_border) %>%
  border_outer(part="all", border = std_border) %>%
  vline(border = std_border ) %>%
  
  # Rename and format the header labels
  set_header_labels(panelist_discipline = "Panelist Discipline",
                    n_votes             = "N Initial Votes",
                    n_perc_diss_votes   = "N (%) dissenting votes") %>%
  bold(bold = TRUE, part="header") %>%
  
  # Adjust the table width
  width(width = 2)

post_diss
```




# ðŸ”´ NOTE

Before we analyze race, we want to know the number and proportion of determinations overall. Secondarily, we will repeat the analysis by race/ethnicity (and probably a bunch of other characteristics). Let's don't drop any rows yet that have NA for race/ethnicity. Only drop rows that have NA for determinations (hopefully, there aren't any).

### Determinations Overall

#### Final determinations for the secondary assessment except when not available (initial assessment in this case)

```{r}
# Create caption/ title
cap_1  <- "Abuse Determinations Overall - Secondary LEAD Assessment (Initial When Unavailable)"


overall_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + abandonment_det + financial_exploitation_det + self_neglect_det + abuse_any, 
               data = final_determination, 
               caption = cap_1)
overall_tab <- t1flex(overall_tab, tablefn = c("qflextable", "flextable", "regulartable"))
overall_tab <- width(overall_tab, width = 3)
overall_tab <- bold(overall_tab, bold = FALSE, part = "all")
overall_tab
```

#### Final determinations for the intial assessment

```{r}
# Create caption/ title
cap_1  <- "Abuse Determinations Overall - Initial LEAD Assessment"


initial_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + self_neglect_det +
                        financial_exploitation_det + abandonment_det + abuse_any, 
               data = final_det_initial, 
               caption = cap_1)
initial_tab <- t1flex(initial_tab, tablefn = c("qflextable", "flextable", "regulartable"))
initial_tab <- width(initial_tab, width = 3)
initial_tab <- bold(initial_tab, bold = FALSE, part = "all")
initial_tab
```

#### Final determinations for the secondary assessment

```{r}
# Create caption/ title
cap_1  <- "Abuse Determinations Overall - Secondary LEAD Assessment"


sec_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + self_neglect_det +
                        financial_exploitation_det + abandonment_det + abuse_any, 
               data = final_det_sec, 
               caption = cap_1)
sec_tab <- t1flex(sec_tab, tablefn = c("qflextable", "flextable", "regulartable"))
sec_tab <- width(sec_tab, width = 3)
sec_tab <- bold(sec_tab, bold = FALSE, part = "all")
sec_tab
```

#### Final determinations for the post detect assessment

```{r}
# Create caption/ title
cap_1  <- "Abuse Determinations Overall - Post-Detect LEAD Assessment"


post_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + self_neglect_det +
                        financial_exploitation_det + abandonment_det + abuse_any, 
               data = final_det_post, 
               caption = cap_1)
post_tab <- t1flex(post_tab, tablefn = c("qflextable", "flextable", "regulartable"))
post_tab <- width(post_tab, width = 3)
post_tab <- bold(post_tab, bold = FALSE, part = "all")
post_tab
```

### Race/ Ethnicity stratified by abuse determination

```{r}
# Remove missing rows for LEAD data
fd_na <- final_determination %>% drop_na(physical_abuse_det: 	
xc_assessment_screened_det)
```


#### Abuse Determination Overall by Race/ Ethnicity
The data set includes the Secondary Assessment (initial When unavailable)

```{r}
# Create caption/ title
cap_1  <- "Race/ Ethnicity by LEAD Assessment Abuse Determination"


race_tab <- table1(~ sode_hispanic_4cat_f + american_indian_or_alaska_native + asian + black_or_african_american + native_hawaiian_or_other_pacific_islander + white + other| abuse_any, 
               data = fd_na, 
               caption = cap_1)
race_tab <- t1flex(race_tab, tablefn = c("qflextable", "flextable", "regulartable"))
race_tab <- width(race_tab, width = 1.5)
race_tab <- bold(race_tab, bold = FALSE, part = "all")
race_tab
```

#### Abuse Determination Overall by Household Income
The data set includes the Secondary Assessment (initial When unavailable)

```{r}
# Create caption/ title
cap_1  <- "Household Income by LEAD Assessment Abuse Determination"


income_tab <- table1(~ sode_income_9cat_f | abuse_any, 
               data = fd_na, 
               caption = cap_1)
income_tab <- t1flex(income_tab, tablefn = c("qflextable", "flextable", "regulartable"))
income_tab <- width(income_tab, width = 1.5)
income_tab <- bold(income_tab, bold = FALSE, part = "all")
income_tab
```

#### MedStar Medic and Detect Status at Initial 911 Call vs LEAD Abuse Determination

```{r}
# Create caption/ title
cap_1  <- "MedStar Medic EM Abuse Determinations"


medic_tab <- table1(~ at_physical_4cat_f + at_sexual_4cat_f + at_emotional_4cat_f + at_neglect_4cat_f + at_abandon_4cat_f + at_financial_4cat_f + at_self_4cat_f + medic_abuse_any,
               data = final_determination,
               caption = cap_1)
medic_tab <- t1flex(medic_tab, tablefn = c("qflextable", "flextable", "regulartable"))
medic_tab <- width(medic_tab, width = 3)
medic_tab <- bold(medic_tab, bold = FALSE, part = "all")
medic_tab
```

```{r}
# Create caption/ title
cap_1  <- "Overall MedStar Medic Abuse Determinations and Detect status at Initial 911 Call by Overall LEAD Determinations"


mvl_tab <- table1(~ medic_abuse_any + xc_detect_status_2cat_f | abuse_any,
               data = fd_na,
               caption = cap_1)
mvl_tab <- t1flex(mvl_tab, tablefn = c("qflextable", "flextable", "regulartable"))
mvl_tab <- width(mvl_tab, width = 1.5)
mvl_tab <- bold(mvl_tab, bold = FALSE, part = "all")
mvl_tab
```

# Create LEAD  Data Analysis Word Document

```{r, echo = FALSE}
# create Word file and object
lead_doc <- read_docx()

# Add title
text_style <- fp_text(font.size = 28)
par_style <- fp_par(text.align = "center")

lead_doc <- body_add_fpar(lead_doc, fpar( ftext("LEAD Data Analysis Tables", prop = text_style), 
                                              fp_p = par_style ) ) %>%
  body_add_par(value = "")

# Add number and proportion of assessments completed by type of assessment table
lead_doc <- lead_doc %>% 
  body_add_flextable(sum_table, align = "left") %>%
  body_add_par(value = "")

# Add similarity percentage table
lead_doc <- lead_doc %>%
  body_add_par("The table below answers the question: When comparing the initial assessment abuse determinations to the other assessments, what is the percentage of determinations that were the same?")%>%
  body_add_par(value = "") %>%
  body_add_flextable(sim_table, align = "left") %>%
  body_add_par(value = "")

# Add final determinations for the secondary assessment except when not available (initial assessment in this case) table
lead_doc <- lead_doc %>% 
  body_add_par("LEAD abuse determination was by majority vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)")%>%
  body_add_par(value = "") %>%
  body_add_flextable(overall_tab, align = "left") %>%
  body_add_par(value = "")

# Add final determinations for the intial assessment table
lead_doc <- lead_doc %>% 
  body_add_flextable(initial_tab, align = "left") %>%
  body_add_par(value = "")

# Add final determinations for the secondary assessment table
lead_doc <- lead_doc %>% 
  body_add_flextable(sec_tab, align = "left") %>%
  body_add_par(value = "")

# Add final determinations for the post detect assessment table
lead_doc <- lead_doc %>% 
  body_add_flextable(post_tab, align = "left") %>%
  body_add_par(value = "")

# Add Abuse Determination Overall by Race/ Ethnicity table
lead_doc <- lead_doc %>% 
  body_add_par("LEAD abuse determination was by majority vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)")%>%
  body_add_par(value = "") %>%
  body_add_flextable(race_tab, align = "left") %>%
  body_add_par(value = "")

# Add Abuse Determination Overall by Household Income Table
lead_doc <- lead_doc %>% 
  body_add_par("LEAD abuse determination was by majority vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)")%>%
  body_add_par(value = "") %>%
  body_add_flextable(income_tab, align = "left") %>%
  body_add_par(value = "")

# Add MedStar Medic EM Abuse Determinations Table
lead_doc <- lead_doc %>% 
  body_add_flextable(medic_tab, align = "left") %>%
  body_add_par(value = "")

# Add MedStar Medic and Detect Status at Initial 911 Call vs LEAD Abuse Determination Table
lead_doc <- lead_doc %>% 
  body_add_par("LEAD abuse determination was by majority vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)")%>%
  body_add_par(value = "") %>%
  body_add_flextable(mvl_tab, align = "left")

# Add the percentage dissenting votes for each panelist discipline tables
lead_doc <- lead_doc %>%
  body_add_par(value = "") %>%
  body_add_flextable(ini_diss, align = "left") %>%
  body_add_par(value = "") %>%
  body_add_flextable(sec_diss, align = "left") %>%
  body_add_par(value = "") %>%
  body_add_flextable(post_diss, align = "left") %>%
  body_add_par(value = "")

# Add the LEAD panelists votes table 
lead_doc <- lead_doc %>%
  body_add_flextable(pan_vote, align = "left") %>%
  body_add_par(value = "")

# print the word document
# print(lead_doc, target = "LEAD_data_analysis_tables.docx")
```

# Export LEAD data feasibility metrics tables and plots into a Word file

```{r}
# create Word file and object
feas_doc <- read_docx()

# Add the Non-congruent Cases Between Initial Assessment Determination and Secondary Assessment table
feas_doc <- feas_doc %>% 
  body_add_flextable(case_table, align = "left") %>%
  body_add_par(value = "")

# Add the Non-congruent Cases Between Initial Assessment Determination and Post-DETECT Assessment table
feas_doc <- feas_doc %>% 
  body_add_flextable(case2_table, align = "left") %>%
  body_add_par(value = "")

# Add the final abuse determination for the initial assessment table
feas_doc <- feas_doc %>% 
  body_add_flextable(initial_tab, align = "left") %>%
  body_add_par(value = "")

# Add the final abuse determination for the secondary assessment table
feas_doc <- feas_doc %>% 
  body_add_flextable(sec_tab, align = "left") %>%
  body_add_par(value = "")

# Add the final abuse determination for the post-DETECT assessment table
feas_doc <- feas_doc %>% 
  body_add_flextable(post_tab, align = "left") %>%
  body_add_par(value = "")

# Add the percentage dissenting votes for each panelist discipline tables
feas_doc <- feas_doc %>%
  body_add_flextable(ini_diss, align = "left") %>%
  body_add_par(value = "") %>%
  body_add_flextable(sec_diss, align = "left") %>%
  body_add_par(value = "") %>%
  body_add_flextable(post_diss, align = "left") %>%
  body_add_par(value = "")

# print the word document
# print(feas_doc, target = "LEAD_data_metric_tables.docx")
```

